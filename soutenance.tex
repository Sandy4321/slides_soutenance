\documentclass[english,xcolor={rgb,dvipsnames,table,usenames}]{beamer}

\mode<presentation> {

\usecolortheme{magpie}

}

\usepackage{colortbl}
\usepackage{cancel}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{colortbl}
\usepackage{pgfplots}
\usepackage{array,multirow,makecell}
\usepackage{dsfont}
\usepackage{stmaryrd}
\usepackage{multicol}
\usepackage{changepage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage[export]{adjustbox}
\usepackage{slashbox}
\usepackage{xcolor}
\usepackage{pict2e}
\usepackage{pifont}
\usepackage{eurosym}
\usepackage{tikz}
\usepackage{ulem}
\usepackage[customcolors]{hf-tikz}
\usetikzlibrary{arrows,intersections,positioning,shapes.arrows,decorations.markings}
\usepackage{hyperref}
\usepackage{mdframed}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[backend=biber,bibencoding=utf8]{biblatex}
\usepackage{animate}
\usepackage{listings}
\usetikzlibrary{calc}
\usetikzlibrary{hobby}
\makeatletter % from https://tex.stackexchange.com/a/283273/121799
% Here we define the comparison macro for pairs (a,b)
% We assume decimal numbers acceptable to \ifdim tests
\long\def\xintdothis #1#2\xintorthat #3{\fi #1}%
\let\xintorthat \@firstofone

\captionsetup[figure]{labelfont={color=orange}}

\long\def\@thirdoffour  #1#2#3#4{#3}%
\long\def\@fourthoffour #1#2#3#4{#4}%

\def\IfFirstPairIsGreaterTF #1#2{\@IfFirstPairIsGreaterTF #1,#2,}%

\def\@IfFirstPairIsGreaterTF #1,#2,#3,#4,{%
    \ifdim #1\p@=#3\p@
       \xintdothis{%
         \ifdim #2\p@>#4\p@\expandafter\@firstoftwo
         \else\expandafter\@secondoftwo\fi}\fi
    \ifdim #1\p@>#3\p@\expandafter\@thirdoffour
                      \else\expandafter\@fourthoffour\fi
    \xintorthat{}%
}%

% not needed for numerical inputs
% \catcode`! 3
% \catcode`? 3

% Here there is a very strange \romannumeral0\romannumeral0, this is
% due to some convoluted scheme to avoid double spaces or no spaces
% in between coordinate pairs. Trust me.
\def\QSpairs {\romannumeral0\romannumeral0\qspairs }%
% first we check if empty list
\def\qspairs   #1{\expandafter\qspairs@a\romannumeral-`0#1(!)(?)}%
\def\qspairs@a #1(#2{\ifx!#2\expandafter\qspairs@abort\else
                        \expandafter\qspairs@b\fi (#2}%
\edef\qspairs@abort #1(?){\space\space}%
%
% we check if empty of single and if not pick up the first as Pivot:
\def\qspairs@b #1(#2)#3(#4){\ifx?#4\xintdothis\qspairs@empty\fi
                   \ifx!#4\xintdothis\qspairs@single\fi
                   \xintorthat \qspairs@separate {}{}{#2}(#4)}%
\def\qspairs@empty  #1(?){ }%
\edef\qspairs@single #1#2#3#4(?){\space\space(#3)}%
\def\qspairs@separate #1#2#3#4(#5)%
{%
    \ifx!#5\expandafter\qspairs@separate@done\fi
    \IfFirstPairIsGreaterTF {#5}{#3}%
          \qspairs@separate@appendtogreater
          \qspairs@separate@appendtosmaller {#5}{#1}{#2}{#3}%
}%
%
\def\qspairs@separate@appendtogreater #1#2{\qspairs@separate {#2 (#1)}}%
\def\qspairs@separate@appendtosmaller #1#2#3{\qspairs@separate {#2}{#3 (#1)}}%
%
\def\qspairs@separate@done\IfFirstPairIsGreaterTF #1#2%
    \qspairs@separate@appendtogreater
    \qspairs@separate@appendtosmaller #3#4#5#6(?)%
{%
    \expandafter\qspairs@f\expandafter
    {\romannumeral0\qspairs@b #4(!)(?)}{\qspairs@b #5(!)(?)}{ (#2)}%
}%
%
\def\qspairs@f #1#2#3{#2#3#1}%
%
% \catcode`! 12
% \catcode`? 12

\makeatother
\makeatletter % from https://tex.stackexchange.com/a/412901/121799
\newcommand{\Distance}[3]{% % from https://tex.stackexchange.com/q/56353/121799
\tikz@scan@one@point\pgfutil@firstofone($#1-#2$)\relax  
\pgfmathsetmacro{#3}{veclen(\the\pgf@x,\the\pgf@y)/28.45274}
}
\makeatother 
\newcount\nbofwords
\makeatletter% from https://tex.stackexchange.com/a/12819/121799
\def\myutil@empty{}
\def\multiwords#1 #2\@nil{% 
 \def\NextArg{#2}%
 \advance\nbofwords by  1 %   
 \expandafter\edef\csname word\@alph\nbofwords\endcsname{#1}% 
 \ifx\myutil@empty\NextArg
     \let\next\@gobble
 \fi
 \next#2\@nil
}%    
\def\GetWords#1{%
   \let\next\multiwords 
   \nbofwords=0 %
   \expandafter\next#1 \@nil %
}% 
\makeatother

\long\def\First(#1,#2){#1}
\long\def\Second(#1,#2){#2}
\tikzset{declare
function={interpolator(\x,\xmin,\xmax,\rmin,\rmax)=(\rmin+\rmax)/2+((\rmin-\rmax)/2)*cos((\x-\xmin)*(180/(\xmax-\xmin)));}}
%\tikzset{declare function={PotatoeRadius(\x,\angleA,\angleB,\angleC,\angleD,\distanceA,\distanceB,\distanceC,\distanceD)=\distanceA+(\x-\angleA)*((\distanceB-\distanceA)/(\angleB-\angleA)+(\x-\angleB)*(((-1)*((\distanceB-\distanceA)/(\angleB-\angleA))+(\distanceC-\distanceB)/(\angleC-\angleB))/(\angleC-\angleA)+(((-1)*(((-1)*((\distanceB-\distanceA)/(\angleB-\angleA))+(\distanceC-\distanceB)/(\angleC-\angleB))/(\angleC-\angleA))+((-1)*((\distanceC-\distanceB)/(\angleC-\angleB))+(\distanceD-\distanceC)/(\angleD-\angleC))/(\angleD-\angleB))*(\x-\angleC))/(\angleD-\angleA)));}}
%(\angleC*(\angleC-\angleD)*\angleD*((\distanceA-\distanceB)*(\angleC-\x)*(\angleD-\x)*\x+pow(\angleA,3)*(-(\angleC*pow(\angleD,2)*\distanceB)+\angleD*(\distanceB-\distanceC)*(\angleD-\x)*\x+\angleC*(\distanceB-\distanceD)*pow(\x,2)+pow(\angleC,2)*(\angleD*\distanceB+(-\distanceB+\distanceD)*\x))+pow(\angleB,3)*(-(\angleA*pow(\angleD,2)*\distanceC)-\angleD*(\distanceA-\distanceC)*(\angleD-\x)*\x+\angleA*(\distanceC-\distanceD)*pow(\x,2)+pow(\angleC,2)*(-(\angleD*\distanceA)+\angleA*\distanceD+\distanceA*\x-\distanceD*\x)+pow(\angleA,2)*(\angleD*\distanceC-\distanceC*\x+\distanceD*\x)+\angleC*(pow(\angleD,2)*\distanceA-pow(\angleA,2)*\distanceD+(-\distanceA+\distanceD)*pow(\x,2)))+pow(\angleA,2)*(-(\angleD*(\distanceB-\distanceC)*(\angleD-\x)*\x*(\angleD+\x))-pow(\angleC,3)*(\angleD*\distanceB+(-\distanceB+\distanceD)*\x)+\angleC*(pow(\angleD,3)*\distanceB+(-\distanceB+\distanceD)*pow(\x,3)))+\angleA*(pow(\angleD,2)*(\distanceB-\distanceC)*(\angleD-\x)*pow(\x,2)+pow(\angleC,3)*(pow(\angleD,2)*\distanceB+(-\distanceB+\distanceD)*pow(\x,2))-pow(\angleC,2)*(pow(\angleD,3)*\distanceB+(-\distanceB+\distanceD)*pow(\x,3)))+pow(\angleB,2)*(\angleD*(\distanceA-\distanceC)*(\angleD-\x)*\x*(\angleD+\x)+pow(\angleC,3)*(\angleD*\distanceA-\angleA*\distanceD-\distanceA*\x+\distanceD*\x)-pow(\angleA,3)*(\angleD*\distanceC+(-\distanceC+\distanceD)*\x)+\angleC*(-(pow(\angleD,3)*\distanceA)+pow(\angleA,3)*\distanceD+(\distanceA-\distanceD)*pow(\x,3))+\angleA*(pow(\angleD,3)*\distanceC+(-\distanceC+\distanceD)*pow(\x,3)))+\angleB*(-(pow(\angleD,2)*(\distanceA-\distanceC)*(\angleD-\x)*pow(\x,2))+pow(\angleC,3)*(-(pow(\angleD,2)*\distanceA)+pow(\angleA,2)*\distanceD+(\distanceA-\distanceD)*pow(\x,2))+pow(\angleA,3)*(pow(\angleD,2)*\distanceC+(-\distanceC+\distanceD)*pow(\x,2))+pow(\angleC,2)*(pow(\angleD,3)*\distanceA-pow(\angleA,3)*\distanceD+(-\distanceA+\distanceD)*pow(\x,3))-pow(\angleA,2)*(pow(\angleD,3)*\distanceC+(-\distanceC+\distanceD)*pow(\x,3))))/((\angleA-\angleB)*(\angleA-\angleC)*(\angleB-\angleC)*(\angleA-\angleD)*(\angleB-\angleD)*(\angleC-\angleD)));}}
\newcommand{\DrawArcAngle}[6][]{% just for emergencies
\pgfmathanglebetweenpoints{\pgfpointanchor{#3}{center}}{\pgfpointanchor{#2}{center}}
\xdef\angleA{\pgfmathresult}
\pgfmathanglebetweenpoints{\pgfpointanchor{#3}{center}}{\pgfpointanchor{#4}{center}}
\xdef\angleB{\pgfmathresult}
\draw[#1] ($(#3)+(\angleA:#5)$) arc [start angle=\angleA,end angle=\angleB,radius=#5]
#6;
}
\newcommand{\DrawPotato}[5][]{
\coordinate (PotatoCenter) at (barycentric cs:#2=1,#3=1,#4=1,#5=1);
\pgfmathanglebetweenpoints{\pgfpointanchor{PotatoCenter}{center}}{\pgfpointanchor{#2}{center}}
\xdef\angleA{\pgfmathresult}
\pgfmathanglebetweenpoints{\pgfpointanchor{PotatoCenter}{center}}{\pgfpointanchor{#3}{center}}
\xdef\angleB{\pgfmathresult}
\pgfmathanglebetweenpoints{\pgfpointanchor{PotatoCenter}{center}}{\pgfpointanchor{#4}{center}}
\xdef\angleC{\pgfmathresult}
\pgfmathanglebetweenpoints{\pgfpointanchor{PotatoCenter}{center}}{\pgfpointanchor{#5}{center}}
\xdef\angleD{\pgfmathresult}

\Distance{(PotatoCenter)}{(#2)}{\distanceA}
\Distance{(PotatoCenter)}{(#3)}{\distanceB}
\Distance{(PotatoCenter)}{(#4)}{\distanceC}
\Distance{(PotatoCenter)}{(#5)}{\distanceD}
\xdef\coordList{(\angleA,\distanceA) (\angleB,\distanceB) (\angleC,\distanceC) (\angleD,\distanceD)}%
\typeout{\coordList}
\xdef\sortedList{\QSpairs{\coordList}}%
\GetWords{\sortedList}
\xdef\NewList{\worda,\wordb,\wordc,\wordd}%
\xdef\NewList{\expandafter\First\worda/\expandafter\Second\worda, 
\expandafter\First\wordb/\expandafter\Second\wordb,
\expandafter\First\wordc/\expandafter\Second\wordc,
\expandafter\First\wordd/\expandafter\Second\wordd}% this list is not used
\xdef\angleA{\expandafter\First\worda}%
\xdef\distanceA{\expandafter\Second\worda}%
\xdef\angleB{\expandafter\First\wordb}%
\xdef\distanceB{\expandafter\Second\wordb}%
\xdef\angleC{\expandafter\First\wordc}%
\xdef\distanceC{\expandafter\Second\wordc}%
\xdef\angleD{\expandafter\First\wordd}%
\xdef\distanceD{\expandafter\Second\wordd}%
\begin{scope}[shift=(PotatoCenter)]
\draw[#1,smooth,samples=50] plot[variable=\x,domain=\angleA:\angleB] %
(\x:{interpolator(\x,\angleA,\angleB,\distanceA,\distanceB)})
-- 
plot[variable=\x,domain=\angleB:\angleC] %
(\x:{interpolator(\x,\angleB,\angleC,\distanceB,\distanceC)})
--
plot[variable=\x,domain=\angleC:\angleD] %
(\x:{interpolator(\x,\angleC,\angleD,\distanceC,\distanceD)})
--
plot[variable=\x,domain=\angleD:{\angleA+360}] %
(\x:{interpolator(\x,\angleD,{\angleA+360},\distanceD,\distanceA)});
\end{scope}
}

\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks,linkcolor=,urlcolor=links}

\tikzset{style green/.style={
    set fill color=green!50!lime!60,
    set border color=white,
  },
  style cyan/.style={
    set fill color=cyan!90!blue!60,
    set border color=white,
  },
  style orange/.style={
    set fill color=orange!80!red!60,
    set border color=white,
  },
  hor/.style={
    above left offset={-0.15,0.31},
    below right offset={0.15,-0.125},
    #1
  },
  ver/.style={
    above left offset={-0.1,0.3},
    below right offset={0.15,-0.15},
    #1
  }
}

\newcommand{\tikzmark}[2][minimum width=6cm,minimum height=1.5cm]{
\tikz[remember picture, overlay]
\node[anchor=west,
inner sep=0pt,
outer sep=6pt,
xshift=-0.5em,
yshift=-3ex,
#1](#2){};
}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\addbibresource{biblio.bib}

\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\setcellgapes{1pt}
\makegapedcells
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash }b{#1}}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash }b{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash }b{#1}}

\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}

\newcommand{\xuparrow}[1]{%
  {\left\uparrow\vbox to #1{}\right.\kern-\nulldelimiterspace}
}

\renewcommand*{\bibfont}{\small}

\tikzset{
  treenode/.style = {shape=rectangle, rounded corners,
                     draw, align=center,
                     top color=white, bottom color=blue!20},
  root/.style     = {treenode, font=\Large, bottom color=red!30},
  env/.style      = {treenode, font=\ttfamily\normalsize},
  dummy/.style    = {circle,draw,color=black}
}

\newcommand\rstyle{%
  \NoAutoSpacing
  \lstset{%
    language=R,
    alsoletter={_},
otherkeywords={install_github},             % Add keywords here
%    basicstyle=\small,
    keywordstyle=\color{blue},
    stringstyle=\color{green},
%    numbers=left,
%    numberstyle=\tiny,
%    numbersep=5pt,
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{blue},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it is 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
    frame=single%
  }%
}

\lstnewenvironment{rlisting}
{\rstyle}{}

\newcommand\rinline[1]{{\rstyle\lstinline!#1!}}

% Allows the use of \toprule, \midrule and \bottomrule in tables

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Soutenance]{Formalisation et étude de problématiques \\ de scoring en risque de crédit \\ {\small Inférence de rejet, discrétisation de variables et interactions, \\ arbres de régression logistique}}

\author{Soutenance de thèse d'Adrien Ehrhardt \\ {\footnotesize
Encadré par Christophe Biernacki, Philippe Heinrich, Vincent Vandewalle
}}

\institute[CACF - Inria]

\date{Villeneuve d'Ascq, 30/09/2019} % Date, can be changed to a custom date

\titlegraphic{%
    \includegraphics[width=2.5cm]{figures/inria.png}~%
    \includegraphics[width=4cm]{figures/logo.png}%
}

\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}

\tikzset{
    myarrow/.style={
        draw,
        fill=orange,
        single arrow,
        minimum height=3.5ex,
        single arrow head extend=1ex
    }
}

\tikzstyle{interrupt}=[
    postaction={
        decorate,
        decoration={markings,
                    mark= at position 0.5 
                          with
                          {
                            \fill[black] (-0.1,-0.3) rectangle (0.1,0.3);
                            \draw (-0.1,0.3) -- (-0.1,-0.3)
                                  (0.1,0.3) -- (0.1,-0.3);
                          }
                    }
                }
]


\addtobeamertemplate{navigation symbols}{}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}

\lstset{language=R}

\newcommand{\appropto}{\mathrel{\vcenter{
  \offinterlineskip\halign{\hfil$##$\cr
    \propto\cr\noalign{\kern2pt}\sim\cr\noalign{\kern-2pt}}}}}

\newcommand\q{{\bm{q}}}
\newcommand\s{q}
\newcommand\Q{\mathcal{Q}}
\newcommand\ag{\bm{\alpha}}
\newcommand{\bth}{\boldsymbol{\theta}} 
\newcommand{\bc}{\boldsymbol{c}} 
\newcommand{\bx}{\boldsymbol{x}} 
\newcommand{\tx}{\textbf{x}}
\newcommand{\bs}{\boldsymbol{s}} 
\newcommand{\ts}{\textbf{s}}
\newcommand{\be}{\boldsymbol{e}} 
\newcommand{\te}{\textbf{e}}
\newcommand{\by}{\boldsymbol{y}} 
\newcommand{\ty}{\textbf{y}}
\newcommand{\f}{\text{f}}
\newcommand{\nf}{\text{nf}}
\newcommand{\yslant}{0.5}
\newcommand{\xslant}{-0.6}
\newcommand{\tr}{T}
\newcommand{\bqk}{\bm{\mathfrak{q}}}

\def\mybar#1#2#3{%%
\begin{tabular}{@{}l@{}} {\scriptsize #1} \\ {\scriptsize #2} \\ {\scriptsize #3} \end{tabular} & \resizebox{.05#1\textwidth}{0.7cm}{\begin{tabular}{@{}l@{}}{\color{green}\rule[0pt]{#1bp}{10pt}} \\ {\color{orange}\rule[0pt]{#2bp}{10pt}} \\ {\color{red}\rule[0pt]{#3bp}{10pt}} \end{tabular}}}

\def\myobar#1#2#3{%%
\begin{tabular}{@{}l@{}} {\scriptsize #1} \\ {\scriptsize #2} \\ {\scriptsize #3} \end{tabular} & \resizebox{.05#2\textwidth}{0.7cm}{\begin{tabular}{@{}l@{}}{\color{orange}\rule[0pt]{#1bp}{10pt}} \\ {\color{green}\rule[0pt]{#2bp}{10pt}} \\ {\color{orange}\rule[0pt]{#3bp}{10pt}}\end{tabular}}}

\pgfmathdeclarefunction{gauss}{2}{\pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}}

\newcommand{\myGlobalTransformation}[2]
{
    \pgftransformcm{1}{0}{0.4}{0.5}{\pgfpoint{#1cm}{#2cm}}
}


\newcommand{\myGlobalTransformationbis}[2]
{
    \pgftransformcm{1}{0}{0.4}{0.3}{\pgfpoint{#1cm}{#2cm}}
}

\newcommand{\gridThreeD}[3]
{
    \begin{scope}
        \myGlobalTransformation{#1}{#2};
        \draw [#3,step=7cm] grid (7,7);
    \end{scope}
}

\tikzstyle myBG=[line width=3pt,opacity=1.0]

\newcommand{\drawLinewithBG}[2]
{
    \draw[white,myBG]  (#1) -- (#2);
    \draw[black,very thick] (#1) -- (#2);
}

\newcommand{\graphLinesHorizontal}
{
    \drawLinewithBG{1,1}{7,1};
    \drawLinewithBG{1,3}{7,3};
    \drawLinewithBG{1,5}{7,5};
    \drawLinewithBG{1,7}{7,7};
}

\newcommand{\graphLinesVertical}
{
    %swaps x and y coordinate (hence vertical lines):
    \pgftransformcm{0}{1}{1}{0}{\pgfpoint{0cm}{0cm}}
    \graphLinesHorizontal;
}

\newcommand{\graphThreeDnodes}[2]
{
    \begin{scope}
        \myGlobalTransformation{#1}{#2};
        \foreach \x in {1,3,5,7} {
            \foreach \y in {1,3,5,7} {
                \node at (\x,\y) [circle,fill=black,scale=0.3] {};
                %this way circle of nodes will not be transformed
            }
        }
    \end{scope}
}

\begin{document}

\frame[plain]{\titlepage}

\begin{frame}
\frametitle{Table of Contents}
\tableofcontents[hideallsubsections]
\end{frame}

\section{Context and notations}

\subsection{industrial setting}

\begin{frame}
\frametitle{\secname: \subsecname}
\only<1-6>{
\begin{table}
\centering
\begin{tiny}
\hspace*{-0.7cm}\begin{tabular}{p{1.7cm}|p{1.1cm}|p{1cm}|p{1.4cm}|p{1.5cm}||p{0.6cm}|p{1cm}}
\textcolor <4,6> {green} {\textbf<4,6>{Job}} & \only<1-3>{Home} & \only<1-3>{Time in job} & \textcolor <4,6> {green} {\textbf<4,6>{Family status}} & \textcolor <4,5> {green} {\textbf<4,5>{Wages}} & \uncover<8->{\textcolor{green}{\textbf{Score}}} & Repayment \\
\hline
\textcolor <4,6> {green} {\textbf<4,6>{\only<1-5>{Craftsman} \only<6->{?+Low-qualified}}} & \only<1-3>{Owner} & \only<1-3>{20} & \textcolor <4,6> {green} {\textbf<4,6>{\only<1-5>{Widower}  \only<6>{?+Alone}}} & \textcolor <4-5> {green} {\textbf<4-5>{\only<1-4>{2000} \only<5->{]1500;2000]}}} & \uncover<8->{\textcolor{green}{\textbf{225}}} & 0  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<1-5>{?} \only<6->{?+Low-qualified}}} & \only<1-3>{Renter} & \only<1-3>{10} & \textcolor <4,6> {green} {\textbf<4,6>{\only<1-5>{Common-law}  \only<6>{Union}}} & \textcolor <4-5> {green} {\textbf<4>{\only<1-4>{1700} \only<5->{]1500;2000]}}} & \uncover<8->{\textcolor{green}{\textbf{190}}} & 1  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<1-5>{Licensed professional} \only<6->{High-qualified}}} & \only<1-3>{Starter} & \only<1-3>{5} & \textcolor <4,6> {green} {\textbf<4,6>{\only<1-5>{Divorced} \only<6>{?+Alone}}} & \textcolor <4-5> {green} {\textbf<4>{\only<1-4>{4000} \only<5->{]2000;$\infty$[}}} & \uncover<8->{\textcolor{green}{\textbf{218}}} & 0  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<1-5>{Executive} \only<6->{High-qualified}}} & \only<1-3>{By work} & \only<1-3>{8} & \textcolor <4,6> {green} {\textbf<4,6>{\only<1-5>{Single} \only<6>{?+Alone}}} & \textcolor <4-5> {green} {\textbf<4>{\only<1-4>{2700} \only<5->{]2000;$\infty$[}}} & \uncover<8->{\textcolor{green}{\textbf{202}}} & 1  \\
\textcolor <3> {green} {\textbf<3>{\only<1-2>{{Office employee}} \only<3->{\cancel{Office employee}}}} &  \textcolor <3> {green} {\textbf<3>{\only<1-2>{Renter} \only<3->{\cancel{Renter}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{12} \only<3->{\cancel{12}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{Married} \only<3->{\cancel{Married}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{1400} \only<3->{\cancel{1400}}}} & \uncover<8->{\textcolor{green}{\textbf{NA}}} & NA  \\
\textcolor <3> {green} {\textbf<3>{\only<1-2>{Worker} \only<3->{\cancel{Worker}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{By family} \only<3->{\cancel{By family}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{2} \only<3->{\cancel{2}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{?} \only<3->{\cancel{?}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{1200} \only<3->{\cancel{1200}}}} & \uncover<8->{{\textbf{NA}}} & NA  \\
\end{tabular}
\end{tiny}
\caption{\label{tab:exemple} Dataset with outliers and missing values.} 
\end{table}
}

\only<7>{
\begin{table}
\centering
\begin{tiny}
\hspace*{-0.7cm}\begin{tabular}{p{2cm}|p{1.1cm}|p{1cm}|p{2.4cm}||p{0.6cm}|p{1cm}}
\textcolor <4,6> {green} {\textbf<4,6>{Job}} & \only<2-3>{Home} & \only<2-3>{Time in job} & \textcolor <7> {green} {\textbf<7>{Family status x Wages}} & \uncover<8->{\textcolor{green}{\textbf{Score}}} & Repayment \\
\hline
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{Craftsman} \only<6->{?+Low-qualified}}} & \only<2-3>{Owner} & \only<2-3>{20} & \textcolor <7> {green} {\textbf<6>{?+Alone x ]1500;2000]}} & \uncover<8->{\textcolor{green}{\textbf{225}}} & 0  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{?} \only<6->{?+Low-qualified}}} & \only<2-3>{Renter} & \only<2-3>{10} & \textcolor <7> {green} {\textbf<7>{Union x ]1500;2000]}} & \uncover<8->{\textcolor{green}{\textbf{190}}} & 1  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{Licensed professional} \only<6->{High-qualified}}} & \only<2-3>{Starter} & \only<2-3>{5} & \textcolor <7> {green} {\textbf<7>{?+Alone x ]2000;$\infty$[}} & \uncover<8->{\textcolor{green}{\textbf{218}}} & 0  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{Executive} \only<6->{High-qualified}}} & \only<2-3>{By work} & \only<2-3>{8} & \textcolor <7> {green} {\textbf<7>{?+Alone x ]2000;$\infty$[}} & \uncover<8->{\textcolor{green}{\textbf{202}}} & 1  \\
\textcolor <3> {green} {\textbf<3>{\only<1-2>{{Office employee}} \only<3->{\cancel{Office employee}}}} &  \textcolor <3> {green} {\textbf<3>{\only<1-2>{Renter} \only<3->{\cancel{Renter}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{12} \only<3->{\cancel{12}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{Married} \only<3->{\cancel{Married}}}} \textcolor <3> {green} {\textbf<3>{\only<1-2>{1400} \only<3->{\cancel{1400}}}} & \uncover<8->{{\textbf{NA}}} & NA  \\
\textcolor <3> {green} {\textbf<3>{\only<1-2>{Worker} \only<3->{\cancel{Worker}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{By family} \only<3->{\cancel{By family}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{2} \only<3->{\cancel{2}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{?} \only<3->{\cancel{?}}}} \textcolor <3> {green} {\textbf<3>{\only<1-2>{1200} \only<3->{\cancel{1200}}}} & \uncover<8->{{\textbf{NA}}} & NA  \\
\end{tabular}
\end{tiny}
\caption{\label{tab:exemple} Dataset with outliers and missing values.}
\end{table}
}

\only<8>{
\begin{table}
\centering
\begin{tiny}
\hspace*{-0.7cm}\begin{tabular}{p{2cm}|p{1.1cm}|p{1cm}|p{2.4cm}||p{0.6cm}|p{1cm}}
\textcolor <4,6> {green} {\textbf<4,6>{Job}} & \only<2-3>{Home} & \only<2-3>{Time in job} & \textcolor <7> {green} {\textbf<7>{Family status x Wages}} & \only<9->{\textcolor{green}{\textbf{Score}}} & Repayment \\
\hline
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{Craftsman} \only<6->{?+Low-qualified}}} & \only<2-3>{Owner} & \only<2-3>{20} & \textcolor <7> {green} {\textbf<6>{?+Alone x ]1500;2000]}} & \only<9->{\textcolor{green}{\textbf{225}}} & 0  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{?} \only<6->{?+Low-qualified}}} & \only<2-3>{Renter} & \only<2-3>{10} & \textcolor <7> {green} {\textbf<7>{Union x ]1500;2000]}} & \only<9->{\textcolor{green}{\textbf{190}}} & 1  \\
\arrayrulecolor{green}\hline
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{Licensed professional} \only<6->{High-qualified}}} & \only<2-3>{Starter} & \only<2-3>{5} & \textcolor <7> {green} {\textbf<7>{?+Alone x ]2000;$\infty$[}} & \only<9->{\textcolor{green}{\textbf{218}}} & 0  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{Executive} \only<6->{High-qualified}}} & \only<2-3>{By work} & \only<2-3>{8} & \textcolor <7> {green} {\textbf<7>{?+Alone x ]2000;$\infty$[}} & \only<9->{\textcolor{green}{\textbf{202}}} & 1  \\
\textcolor <3> {green} {\textbf<3>{\only<1-2>{{Office employee}} \only<3->{\cancel{Office employee}}}} &  \textcolor <3> {green} {\textbf<3>{\only<1-2>{Renter} \only<3->{\cancel{Renter}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{12} \only<3->{\cancel{12}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{Married} \only<3->{\cancel{Married}}}} \textcolor <3> {green} {\textbf<3>{\only<1-2>{1400} \only<3->{\cancel{1400}}}} & \only<9->{{\textbf{NA}}} & NA  \\
\textcolor <3> {green} {\textbf<3>{\only<1-2>{Worker} \only<3->{\cancel{Worker}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{By family} \only<3->{\cancel{By family}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{2} \only<3->{\cancel{2}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{?} \only<3->{\cancel{?}}}} \textcolor <3> {green} {\textbf<3>{\only<1-2>{1200} \only<3->{\cancel{1200}}}} & \only<9->{{\textbf{NA}}} & NA  \\
\end{tabular}
\end{tiny}
\caption{\label{tab:exemple} Dataset with outliers and missing values.}
\end{table}
}

\only<9->{
\begin{table}
\centering
\begin{tiny}
\hspace*{-0.7cm}\begin{tabular}{p{2cm}|p{1.1cm}|p{1cm}|p{2.4cm}||p{0.6cm}|p{1cm}}
\textcolor <4,6> {green} {\textbf<4,6>{Job}} & \only<2-3>{Home} & \only<2-3>{Time in job} & \textcolor <7> {green} {\textbf<7>{Family status x Wages}} & \uncover<9->{\textcolor{green}{\textbf{Score}}} & Repayment \\
\hline
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{Craftsman} \only<6->{?+Low-qualified}}} & \only<2-3>{Owner} & \only<2-3>{20} & \textcolor <7> {green} {\textbf<6>{?+Alone x ]1500;2000]}} & \uncover<9->{\textcolor{green}{\textbf{225}}} & 0  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{?} \only<6->{?+Low-qualified}}} & \only<2-3>{Renter} & \only<2-3>{10} & \textcolor <7> {green} {\textbf<7>{Union x ]1500;2000]}} & \uncover<9->{\textcolor{green}{\textbf{190}}} & 1  \\
\hline
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{Licensed professional} \only<6->{High-qualified}}} & \only<2-3>{Starter} & \only<2-3>{5} & \textcolor <7> {green} {\textbf<7>{?+Alone x ]2000;$\infty$[}} & \uncover<9->{\textcolor{green}{\textbf{218}}} & 0  \\
\textcolor <4,6> {green} {\textbf<4,6>{\only<2-5>{Executive} \only<6->{High-qualified}}} & \only<2-3>{By work} & \only<2-3>{8} & \textcolor <7> {green} {\textbf<7>{?+Alone x ]2000;$\infty$[}} & \uncover<9->{\textcolor{green}{\textbf{202}}} & 1  \\
\textcolor <3> {green} {\textbf<3>{\only<1-2>{{Office employee}} \only<3->{\cancel{Office employee}}}} &  \textcolor <3> {green} {\textbf<3>{\only<1-2>{Renter} \only<3->{\cancel{Renter}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{12} \only<3->{\cancel{12}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{Married} \only<3->{\cancel{Married}}}} \textcolor <3> {green} {\textbf<3>{\only<1-2>{1400} \only<3->{\cancel{1400}}}} & \uncover<9->{{\textbf{NA}}} & NA  \\
\textcolor <3> {green} {\textbf<3>{\only<1-2>{Worker} \only<3->{\cancel{Worker}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{By family} \only<3->{\cancel{By family}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{2} \only<3->{\cancel{2}}}} & \textcolor <3> {green} {\textbf<3>{\only<1-2>{?} \only<3->{\cancel{?}}}} \textcolor <3> {green} {\textbf<3>{\only<1-2>{1200} \only<3->{\cancel{1200}}}} & \uncover<9->{{\textbf{NA}}} & NA  \\
\end{tabular}
\end{tiny}
\caption{\label{tab:exemple} Dataset with outliers and missing values.}
\end{table}
}

\vspace{-0.5cm}
\uncover<2->{
\begin{enumerate}
\item \textcolor <3> {green} {\textbf<3>{Discarding rejected applicants}}
\item \textcolor <4> {green} {\textbf<4>{Feature selection}}
\item \textcolor <5> {green} {\textbf<5>{Discretization}} / \textcolor <6> {green} {\textbf<6>{grouping}}
\item \textcolor <7> {green} {\textbf<7>{Interaction screening}}
\item \textcolor <8> {green} {\textbf<8>{Segmentation}}
\item \textcolor <9> {green} {\textbf<9>{Logistic regression fitting}}
\end{enumerate}
}
\end{frame}


\subsection{available data}

\begin{frame}
\frametitle{\secname: \subsecname}

Random variables: $\bm{X}, Y, Z$.

\bigskip

\uncover<2->{
\begin{block}{Observations}
\vspace*{-0.8cm}
\begin{alignat*}{3}
\bm{x} & = (x_1, \dots, x_d) && \text{characteristics,} \\
x_j & \in \mathbb{R} \textit{ or } \{1, \dots, l_j\} \quad && \text{\textit{e.g.}\ rent amount, job, \dots,} \\
y & \in \{0,1\} \quad && \text{good or bad,} \\
z & \in \{\f,\nf\} \quad && \text{financed or not financed.}
\end{alignat*}
\vspace*{-0.6cm}
\end{block}
}

%\bigskip
%
%\uncover<3->{
%True distribution of good and bad clients: $p(y | \bm{x})$.
%}

\bigskip

\uncover<3->{
\begin{block}{Samples}
\vspace*{-0.8cm}
\begin{alignat*}{3}
\mathcal{T}_{\text{f}} & = (\bm{\mathbf{x}}_{\text{f}}, \bm{\mathbf{y}}_{\text{f}}, \bm{\mathbf{z}}_{\text{f}}) \quad && n \text{-sample of financed clients,} \\
\mathcal{T}_{\text{nf}} & = (\bm{\mathbf{x}}_{\text{nf}}, \bm{\mathbf{z}}_{\text{nf}}) \quad && n' \text{-sample of not-financed clients,} \\
\mathcal{T} & = \mathcal{T}_{\text{f}} \cup \mathcal{T}_{\text{nf}} \quad && \text{observed sample,} \\
\mathcal{T}_{\text{c}} & = \mathcal{T} \cup \bm{\mathbf{y}}_{\text{nf}} \quad && \text{complete sample.}
\end{alignat*}
\vspace*{-0.6cm}
\end{block}
}

\end{frame}




\begin{frame}
\frametitle{\secname: \subsecname}

The observed data are the following:

\setbeamercolor{normal text}{fg=black}
\usebeamercolor[fg]{normal text}


\[ \hspace{-0.8cm} \textcolor{white}{\mathcal{T} =} \begin{array}{c}
\textcolor{white}{\mathcal{T}_{\f} = \bigg(} \; \tikzmarkin[hor=style green]{el02} \mathbf{x}_{\f} \tikzmarkend{el02} \\
%\\
\textcolor{white}{\cup} \\
%\\
\textcolor{white}{\mathcal{T}_{\nf} = \bigg(} \; \tikzmarkin[hor=style orange]{el-12} \mathbf{x}_{\nf} \tikzmarkend{el-12} \end{array}
%{\color{white} \bigg(} 
\begin{array}{ccc}
\tikzmarkin[hor=style green]{e1} \; \; x_{1,1} & \cdots & x_{1,d} \\
 \vdots & \vdots & \vdots  \\
 x_{n,1} & \cdots & x_{n,d} \tikzmarkend{e1} \\
\tikzmarkin[hor=style orange]{e2} \; \; x_{n+1,1} & \cdots & x_{n+1,d}  \\
 \vdots & \vdots & \vdots \\
 x_{n+n',1} & \cdots & x_{n+n',d} \tikzmarkend{e2} \end{array} %{\color{white} \bigg),}
 \hspace{0.5cm}
 \begin{array}{c}
\tikzmarkin[hor=style green]{el11} \mathbf{y}_{\f} \tikzmarkend{el11} \\
\\
\\
\\
\tikzmarkin[hor=style orange]{el12} \mathbf{y}_{\nf} \tikzmarkend{el12}\end{array}
%\left( 
\begin{array}{c}
\tikzmarkin[hor=style green]{e4} y_1 \\
\vdots \\
y_n \tikzmarkend{e4} \\ 
\tikzmarkin[hor=style orange]{e3} \text{NA} \\
\vdots \\
\text{NA} \tikzmarkend{e3} \end{array} %\textcolor{white}{\right),}
 \hspace{0.5cm}
 \begin{array}{c}
\tikzmarkin[hor=style green]{el5} \mathbf{z}_{\f} \tikzmarkend{el5} \\
\\
\\
\\
\tikzmarkin[hor=style orange]{el6} \mathbf{z}_{\nf} \tikzmarkend{el6} \end{array}
%\left( 
\begin{array}{c}
\tikzmarkin[hor=style green]{e8} \text{f} \\
\vdots \\
\text{f} \tikzmarkend{e8} \\ 
\tikzmarkin[hor=style orange]{e9} \text{nf} \\
\vdots \\
\text{nf} \tikzmarkend{e9} \end{array} % \right)
 \hspace{0.2cm}
 \begin{array}{c}
\textcolor{white}{\bigg).} \\
\\
%\\
\\
\textcolor{white}{\bigg).} \end{array}
\]

\setbeamercolor{normal text}{fg=white}
\usebeamercolor[fg]{normal text}

\medskip

\uncover<2->{
%Need for a {\bf computable model} that resembles $p$, often in the form of a {\bf parametric} model $p_{\bm{\theta}}(y | \bm{x})$, which we can calculate for a new client.
\textit{Credit Scoring} aims at estimating $p(y | \bm{x})$ in the form of a simple {\bf parametric} model $p_{\bm{\theta}}(y | \bm{x})$ such as logistic regression:
}

\medskip

\uncover<3->{
%Example: logistic regression 
\[ \ln \frac{p_{\bm{\theta}}(1 | \bm{x})}{1 - p_{\bm{\theta}}(1 | \bm{x})} = (1,\bm{x})' \bm{\theta}. \]
}

%\medskip
%
%\uncover<3->{
%There is $\bm{\theta}^\star$ that makes $p_{\bm{\theta}^\star}$ ``close'' to $p$.
%
%$\bm{\theta}^\star = \argmin_{\bm{\theta}} \mathbb{E}_{\bm{X}} [\text{KL}(p || p_{\bm{\theta}})] = \int_{\mathcal{X}} \sum_{y \in \{0,1\}} p(y | \bm{x}) \ln \dfrac{p(y | \bm{x})}{p_{\bm{\theta}}(y | \bm{x})}$.
%
%\begin{block}{Well-specified model assumption}
%$\mathbb{E}_{\bm{X}} [\text{KL}(p || p_{\bm{\theta}^\star})] = 0,$
%
%$p_{\bm{\theta}^\star}(y | \bm{x}) = p(y | \bm{x}).$
%\end{block}
%}

\end{frame}


%\subsection{Estimation}
%\begin{frame}
%\frametitle{\secname: \subsecname}
%
%\end{frame}




%\begin{frame}
%\frametitle{\secname: \subsecname}
%
%\begin{figure}
%\begin{center}
%\resizebox{0.8\textwidth}{4.7cm}{
%\begin{tikzpicture}[scale=1.1,every node/.style={minimum size=1cm},on grid]
%
%	% Real level
%	\begin{scope}[
%		yshift=-120,
%		every node/.append style={yslant=\yslant,xslant=\xslant},
%		yslant=\yslant,xslant=\xslant
%	] 
%		% The frame:
%		\draw[white, dashed, thin] (0,0) rectangle (7,7); 
%		% Agents:
%		\draw[fill=red]  
%			%(5,2) circle (.1) % Firms
%			(2,2) circle (.1); % Households
%		% Flows:
%		%\draw[-latex,thin, blue] 
%			%(2,2.2) to (2,4); % Labour Powers
%		%\draw[-latex,thin, blue]
%			%(4.85,1.85) to (4,1); % Wages
%		 % Labels:
%		\fill[white]
%			(0.5,6.5) node[right, scale=2.5] {Space $\Theta$}	
%			(2.1,1.9) node[below,scale=2]{$\bm{\theta}^\star$};
%
%	\end{scope}
%	
%	% 2 vertical lines for linking agents on the 2 levels
%	%\draw[thin, dashed, red](.8,1.75) to (3.8,-0.32);
%	\draw[thin, dashed, red](.8,1.75) to (.8,-1.8);
%	
%    % Draw right angle scheme
%    \draw(.8,-1.6) to (1,-1.6);
%    \draw(1,-1.6) to (1,-1.8);
%
%
%	% Monetary level
%	\begin{scope}[
%		yshift=-20,
%		every node/.append style={yslant=0,xslant=0},
%		yslant=\yslant,xslant=\xslant
%	]
%		 % Agents:
%		\draw [fill=olive]
%			(2,2) circle (.1); % Households
%		 % Labels:
%		\fill[black]
%			(2.2,2.4) node[right,scale=2]{\textcolor{olive}{$p(y|x)$}};
%        \fill[red]
%			(0.85,0.35) node [right, scale=1.5] {Model bias};	
%
%	\end{scope} 
%\end{tikzpicture}
%}
%\end{center}
%%\caption{\label{fig:projection} Vision géométrique du biais de modèle.}
%\end{figure}
%
%
%\end{frame}






%\begin{frame}
%\frametitle{\secname: \subsecname}
%
%$p$ is unknown: access to an i.i.d.\ $n+n'$-sample $\mathcal{T} = (\bm{x}_i, y_i, z_i)_1^{n+n'} \sim p$.
%
%\medskip
%
%\uncover<2->{
%We can deduce from the KL divergence the (log-)likelihood:
%\[ \ell(\bm{\theta} ; \mathcal{T}) = \sum_{i=1}^{n+n'} \ln p_{\bm{\theta}}(y_i | \bm{x}_i). \]
%}
%
%\medskip
%
%\uncover<3->{
%The MLE $\hat{\bm{\theta}} = \argmax_{\bm{\theta}} \ell(\bm{\theta} ; \mathcal{T})$ is a good approximation of $\bm{\theta}^\star$.
%}
%
%\medskip
%
%\uncover<4->{
%Unfortunately, $\hat{\bm{\theta}}$ is not directly computable (no closed form solution).
%}
%
%\medskip
%
%\uncover<5->{
%\[ \tilde{\bm{\theta}} = \text{Newton-Raphson}(\ell(\bm{\theta} ; \mathcal{T})) \neq \hat{\bm{\theta}}. \]
%}
%
%\end{frame}
%
%
%\begin{frame}
%\frametitle{\secname: \subsecname}
%
%
%\begin{figure}
%\begin{center}
%\resizebox{0.8\textwidth}{4.7cm}{
%\begin{tikzpicture}[scale=1.1,every node/.style={minimum size=1cm},on grid]
%
%	% Real level
%	\begin{scope}[
%		yshift=-120,
%		every node/.append style={yslant=\yslant,xslant=\xslant},
%		yslant=\yslant,xslant=\xslant
%	] 
%		% The frame:
%		\draw[white, dashed, thin] (-0.5,-0.5) rectangle (6.5,6.5); 
%		% Agents:
%		\draw[fill=red]  
%			%(5,2) circle (.1) % Firms
%			(2,2) circle (.1); % Households
%		% Flows:
%		\draw[-latex,thin, blue] 
%			(2,2.2) to (2,4); % Labour Powers
%		\draw[-latex,thin, orange]
%			(2,4) to (1,5); % Wages
%		 % Labels:
%		\fill[white]
%			(0.2,6) node[right, scale=2.5] {Space $\Theta$}
%			(2.1,1.9) node[below,scale=2]{$\bm{\theta}^\star$}
%			(2.2,4.3) node [scale=2] {$\hat{\bm{\theta}}$} ;
%		\fill[blue]
%			(0.7,3) node [scale=1] {Bias and variance}
%            (0.5,2.7) node [scale=1] {of estimation};
%         \fill[orange]
%			(0.5,4.2) node [scale=1] {Comp.}
%			(0.5,3.8) node [scale=1] {precision};
%
%		%\fill[blue]
%			%(5.7,1.1) node [scale=1] {Estimation}
%           % (5.7,0.8) node [scale=1] {bias+variance};
%
%	\end{scope}
%	
%	% 2 vertical lines for linking agents on the 2 levels
%	%\draw[thin, dashed, red](.8,1.75) to (3.8,-0.32);
%	\draw[thin, dashed, red](.8,1.75) to (.8,-1.8);
%	
%    % Draw right angle scheme
%    \draw(.8,-1.6) to (1,-1.6);
%    \draw(1,-1.6) to (1,-1.8);
%
%
%	% Monetary level
%	\begin{scope}[
%		yshift=-20,
%		every node/.append style={yslant=0,xslant=0},
%		yslant=\yslant,xslant=\xslant
%	]
%		 % Agents:
%		\draw [fill=olive]
%			(2,2) circle (.1); % Households
%		 % Labels:
%		\fill[black]
%			(2.2,2.1) node[right,scale=2]{\textcolor{olive}{$p(y|x)$}};
%        \fill[red]
%			(0.85,0.35) node [right, scale=1.5] {Model bias};	
%
%	\end{scope} 
%\end{tikzpicture}
%}
%\end{center}
%%\caption{\label{fig:projection2} Vision géométrique du biais de modèle, biais et variance d'estimation.}
%\end{figure}
%
%All of this is ``hidden'' in your favourite statistical language / package / library but is essential to understanding Reject Inference.
%
%\end{frame}
%
%
%
%
%
%
%\subsection{Feature / model selection}
%
%\begin{frame}
%\frametitle{\secname: \subsecname}
%
%Up to now, we assumed a parameter space $\Theta$ {\bf fixed}.
%
%\medskip
%
%\uncover<2->{
%Comparing models = different parameter spaces $\Theta^1, \Theta^2, \dots$ 
%
%Corresponding to feature subsets, different discretizations, interactions, \dots since {\bf we don't know which parameter space is closest to the ``truth''} $p$.
%}
%
%\medskip
%
%\uncover<3->{
%\begin{block}{Model selection tools}
%\[ \hat{\bm{\theta}}^{\text{best}} = \argmin_{\hat{\bm{\theta}}^k \in \Theta^k} \text{BIC}(\hat{\bm{\theta}}^k) = - 2\ell(\hat{\bm{\theta}}^k, \mathcal{T}) + \text{dim}(\Theta^k) \ln n .\]
%\end{block}
%}
%
%\medskip
%
%\uncover<4->{
%BIC has nice statistical properties (consistency) but can be swapped in the entire presentation with your favourite model selection tool like Gini on $\mathcal{T}^{\text{test}}$.
%}
%
%\end{frame}





\section{Reject Inference}

\subsection{industrial setting}

\begin{frame}
\frametitle{\secname: \subsecname}

\begin{figure}[ht]
\begin{minipage}[c]{0.45\linewidth}
\center \includegraphics[width=5cm]{figures/schema.png}
\caption{Simplified financing mechanism in~Crédit Agricole Consumer Finance}
\label{fig:figure1}

\end{minipage}%
\hfil \begin{minipage}[c]{0.5\linewidth}

\center \includegraphics[width=5cm]{figures/camembert_invert.png}
\caption{Proportion of ``final'' lending decisions for CACF France}

\end{minipage}
\end{figure}

\end{frame}


\begin{frame}
\frametitle{\secname: \subsecname}

We traditionally build a logistic regression using only financed clients ({\bf fixed parameter space $\Theta$}):
\[ \hat{\bm{\theta}}_{\f} = \argmax_{\bm{\theta}} \ell(\bm{\theta} ; \mathcal{T}_\f) = \sum_{i=1}^n \ln p_{\bm{\theta}}(y_i | \bm{x}_i), \]
which asymptotically approximates:
\[ \bm{\theta}_{\f}^\star = \argmin_{\bm{\theta}} \mathbb{E}_{\bm{X}} [\text{KL}(p || p_{\bm{\theta}}) | Z = \f]. \]

\end{frame}



\begin{frame}
\frametitle{\secname: \subsecname}

We wish we had:
\[ \hat{\bm{\theta}} = \argmax_{\bm{\theta}} \ell(\bm{\theta} ; \mathcal{T}_{\text{c}}), \]
which asymptotically approximates:
\begin{align*}
\bm{\theta}^\star & = \argmin_{\bm{\theta}} \mathbb{E}_{\bm{X}} [\text{KL}(p || p_{\bm{\theta}})] \\
& = \argmax_{\bm{\theta}} \mathbb{E}_{\bm{x}, y \sim p} [\ln p_{\bm{\theta}}(y | \bm{x})].
\end{align*}
But we lack $\mathbf{y}_{\nf}$.
\vspace*{-0.8cm}
\begin{center}
\resizebox{0.8\textwidth}{4.7cm}{
\begin{tikzpicture}[scale=1.1,every node/.style={minimum size=1cm},on grid]

	% Real level
	\begin{scope}[
		yshift=-120,
		every node/.append style={yslant=\yslant,xslant=\xslant},
		yslant=\yslant,xslant=\xslant
	] 
		% The frame:
		\draw[white, dashed, thin] (0,0) rectangle (7,7); 
		% Agents:
		\draw[fill=orange]  
			(5,2) circle (.1) % Firms
			(2,2) circle (.1); % Households
		% Flows:
		\draw[-latex,thin, yellow] 
			(2,2.2) to (2,4); % Labour Powers
		\draw[-latex,thin, yellow]
			(4.85,1.85) to (4,1); % Wages
		 % Labels:
		\fill[white]
			(0.5,6.5) node[right, scale=2.5] {Model space $\Theta$}	
			(4.9,1.9) node[right,scale=2]{$\theta_{\f}^\star$}
			(2.1,1.9) node[below,scale=2]{$\theta^\star$}
			(2.2,4.3) node [scale=2] {$\hat{\theta}$} 
			(4.2,0.6) node [scale=2] {$\hat{\theta}_{\f}$};
		\fill[yellow]
			(1,3) node [scale=1] {Estimation}
            (1,2.7) node [scale=1] {bias+variance};
		\fill[yellow]
			(5.7,1.1) node [scale=1] {Estimation}
            (5.7,0.8) node [scale=1] {bias+variance};

	\end{scope}
	
	% 2 vertical lines for linking agents on the 2 levels
	\draw[thin, dashed, orange](.8,1.75) to (3.8,-0.32);
	\draw[thin, dashed, orange](.8,1.75) to (.8,-1.8);
	
    % Draw right angle scheme
    \draw(.8,-1.6) to (1,-1.6);
    \draw(1,-1.6) to (1,-1.8);


	% Monetary level
	\begin{scope}[
		yshift=-20,
		every node/.append style={yslant=0,xslant=0},
		yslant=\yslant,xslant=\xslant
	]
		 % Agents:
		\draw [fill=green]
			(2,2) circle (.1); % Households
		 % Labels:
		\fill[black]
			(2.2,2.4) node[right,scale=2]{\textcolor{green}{$p(y|\bm{x})$}};
%			(4,2) node[right,scale=2]{\textcolor{olive}{$p(y|\bm{x}, z = \f)$}};
        \fill[orange]
			(0.85,0.35) node [right, scale=1.5] {Model bias};	

	\end{scope} 
\end{tikzpicture}
}
\end{center}


\end{frame}



\subsection{modelling the financing mechanism}

\begin{frame}
\frametitle{\secname : \subsecname}

Due to the financing mechanism, labels $y$ are not MCAR.

\medskip

\uncover<2->{
Suppose there is some hidden financing mechanism belonging to a parametrized family $\{p_{\bm{\phi}}(z | \bm{x}, y)\}_{\bm{\phi} \in \bm{\Phi}}$.
}

\medskip

\uncover<3->{
Combining financing and credit-worthiness probability distributions:
\[ p_{\bm{\gamma}}(y,z | \bm{x}) = p_{\bm{\theta}(\bm{\gamma})}(y | \bm{x}) p_{\bm{\phi}(\bm{\gamma})}(z | \bm{x}, y). \]
}

%\medskip

\uncover<4->{
To estimate $\bm{\gamma}$, we could rely on Maximum Likelihood theory and maximize:
\[ \ell(\bm{\gamma}; \mathcal{T}) = \sum_{i = 1}^n \ln p_{\bm{\gamma}}(y_i,\f | \bm{x}_i) + \sum_{i=n'}^{n+n'} \ln \sum_{y \in \{0,1\}} p_{\bm{\gamma}}(y,\nf | \bm{x}_i), \]
\textit{e.g.}\ \textit{via} an EM algorithm.
}

\end{frame}






\subsection*{missingness mechanism}

\begin{frame}
\frametitle{\secname : \subsecname}

\begin{itemize}
\item \textbf{Ignorability}: no functional dependence between $\bm{\theta}$ and $\bm{\phi}$, \textit{e.g.}\ $\bm{\gamma} = (\bm{\theta},\bm{\phi})$.

\item<2-> \textbf{MAR}: $\forall \: \bm{x},y,z, \; p(z| \bm{x},y) = p(z| \bm{x})$

$\rightarrow$ Financing is determined by an old score: $Z = \mathds{1}_{\{\bm{\theta}'X > \text{cut}\}}$.

\item<3-> \textbf{MNAR}: $\exists \: \bm{x},y,z, \; p(z| \bm{x},y) \neq p(z| \bm{x})$

$\rightarrow$ Operators' hidden ``feeling'' features $\tilde{\bm{X}}$ influence the financing.

$\rightarrow$ Expert rules based on both present and hidden features $\bm{X}$ and $\tilde{\bm{X}}$ resp.\ where $\tilde{\bm{X}}$ cannot be totally explained by $\bm{X}$.
\end{itemize}

\uncover<4->{
\begin{figure}
\begin{tikzpicture}

\tikzset{vertex/.style = {shape=circle,draw,minimum size=1.5em}}
\tikzset{edge/.style = {->,> = latex'}}
% vertices
\node[vertex] (y) at  (0,0) {$Y$};
\node[vertex] (x) at  (2,-1) {$\bm{X}$};
\node[vertex] (xc) at  (2,1) {$\tilde{\bm{X}}$};
\node[vertex] (z) at (4,0) {$Z$};

edges
\draw[edge] (y) to (x);
\draw[edge] (y) to (xc);
\draw[dashed] (xc) to (x);
\draw[edge] (xc) to (z);
\draw[edge] (x) to (z);

\end{tikzpicture}
\label{fig:mar}
\caption{Dependencies between random variables $Y$, $\bm{\tilde{X}}$, $\bm{X}$ and $Z$}
\end{figure}
}
\end{frame}



\subsection{flawed model selection}

\begin{frame}
\frametitle{\secname : \subsecname}

Because no test-sample $\mathcal{T}^{\text{test}}$ is available from $p(\bm{x}, y, z)$, we cannot resort to error-rate criteria.

\medskip

\uncover<2->{
We should use information criteria on the observed data $\mathcal{T}$ such as:
\[ \text{BIC}(\hat{\bm{\gamma}};\mathcal{T}) = -2 \ell(\hat{\bm{\gamma}}; \mathcal{T}) + \text{dim}(\bm{\Gamma})\ln n, \]
where $\hat{\bm{\gamma}} = \argmax_{\bm{\gamma}} \ell(\bm{\gamma}; \mathcal{T})$, to compare models.
}

\medskip

\uncover<3->{
It requires to precisely state the models $\{ p_{\bm{\gamma}}(y,z | \bm{x})\}_{\bm{\Gamma}}$ that compete and underlying assumptions.
}

\end{frame}



\subsection{reject inference strategies}

\begin{frame}
\frametitle{\secname : \subsecname}

We gathered 6 so-called Reject Inference methods from the literature~\cite{economix,saporta,RI6,banasik} that aim at re-injecting $\bm{\mathbf{x}}_{\nf}$ into the estimation procedure of $\bm{\theta}$.

\medskip

They usually resemble EM-like algorithms:

\setbeamercolor{normal text}{fg=black}
\usebeamercolor[fg]{normal text}

\[ \hspace*{-0.8cm}\textcolor{white}{\mathcal{T}_{\text{c}}^{(1)} = {\Huge \Bigg(}}
%\begin{array}{c}
%\tikzmarkin[hor=style green]{el0} \mathbf{x}_{\f} \tikzmarkend{el0} \\
%\\
%\\
%\tikzmarkin[hor=style green]{el-1} \mathbf{x}_{\nf} \tikzmarkend{el-1} \end{array}
\textcolor{white}{{\Huge \Bigg(}}
\begin{array}{ccc}
\tikzmarkin[hor=style green]{el1} \; \; x_{1,1} & \cdots & x_{1,d}  \\
 \vdots & \vdots & \vdots \\
 x_{n,1} & \cdots & x_{n,d} \\
 x_{n+1,1} & \cdots & x_{n+1,d}  \\
 \vdots & \vdots & \vdots \\
 x_{n+n',1} & \cdots & x_{n+n',d} \tikzmarkend{el1} \end{array} \textcolor{white}{{\Huge \Bigg)},}
 %\hspace{0.2cm}
% \begin{array}{c}
%\tikzmarkin[hor=style green]{l1} \mathbf{y}_{\f} \tikzmarkend{l1}\\
%\\
%\\
%\tikzmarkin[hor=style green]{l2} \mathbf{y}_{\nf} \tikzmarkend{l2} \end{array}
\textcolor{white}{{\Huge \Bigg(}}
\begin{array}{c}
\tikzmarkin[hor=style green]{l3} \; \; y_1 \; \; \; \\
\vdots \\
 y_n \\ 
 \hat{y}_{n+1}^{(1)} \\
\vdots \\
\hat{y}_{n+n'}^{(1)} \tikzmarkend{l3}\end{array} \textcolor{white}{{\Huge \Bigg)},}
%\hspace{0.2cm} 
% \begin{array}{c}
%\tikzmarkin[hor=style green]{el111} \mathbf{z}_{\f} \tikzmarkend{el111}\\
%\\
%\\
%\tikzmarkin[hor=style green]{el121} \mathbf{z}_{\nf} \tikzmarkend{el121}\end{array}
\textcolor{white}{{\Huge \Bigg(}}
\begin{array}{c}
\tikzmarkin[hor=style green]{e41} \text{f} \\
\vdots \\
\text{f} \\ 
\text{nf} \\
\vdots \\
\text{nf} \tikzmarkend{e41} \end{array} \textcolor{white}{{\Huge \Bigg) \Bigg)}}\]
 
\setbeamercolor{normal text}{fg=white}
\usebeamercolor[fg]{normal text}

\end{frame}



\subsection{theoretical findings}

\begin{frame}
\frametitle{\secname : \subsecname}

Fuzzy augmentation and Twins produce the same coefficient $\hat{\bm{\theta}}_{\text{f}}$.

\medskip

Reclassification is equivalent to a Classification-EM algorithm, thus introducing a bias in the estimation of $\bm{\theta}$.

\begin{table}
\caption{Summary of potential biases.}
\begin{center}
\begin{tabular}{L{2cm} | C{4cm} | C{4cm}}
 & MAR & MNAR \\
 \hline
 Well-specified model & $\hat{\bm{\theta}}_{\text{f}}$ is asymptotically unbiased. & \multirowcell{2}{$\hat{\bm{\theta}}_{\text{f}}$ is asymptotically \\ biased. Any correction  \\ relies on \textit{a priori} \\ unverifiable assumptions \\ about $p_{\bm{\phi}}(z | \bm{x}, y)$.} \\
 \cline{1-2}
 Misspecified model & $\hat{\bm{\theta}}_{\text{f}}$ is asymptotically biased: the Augmentation method could be suitable but introduces a new estimation procedure. & \\
\end{tabular}
\end{center}
\end{table}

\end{frame}



\subsection{some simulations}

\begin{frame}
\frametitle{\secname : \subsecname}

\begin{figure}[!ht]
\centering \resizebox{.8\textwidth}{!}{\input{CODE_FIGURES/electronics.tex}}
\caption{Electronics loans dataset from CACF.}
\label{fig:darty_reject}
\end{figure}
\vspace*{-1cm}
\begin{figure}[!ht]
\centering \resizebox{.8\textwidth}{!}{\input{CODE_FIGURES/standard.tex}}
\caption{Standard loans dataset from CACF.}
\label{fig:M3_reject}
\end{figure}

\end{frame}





%\subsection{What is at stake?}
%
%\begin{frame}
%\frametitle{\secname : \subsecname}
%\textbf{Estimators :}
%
%\hspace*{-0.2cm}\begin{alignat*}{6}
%& \text{``Oracle'':} & \sqrt[]{n+n'} && ( \hat{\bm{\theta}} - \bm{\theta}^\star ) &&& \xrightarrow[n,n' \to \infty]{\mathcal{L}} &&& \mathcal{N}_{d+1} (0,{\Sigma}_{\bm{\theta}^\star}) \\
%& \text{Current methodology:} & \sqrt[]{n} && ( \hat{\bm{\theta}}_{\f} - \bm{\theta}^\star_{\f} ) &&& \xrightarrow[n \to \infty]{\mathcal{L}} &&& \mathcal{N}_{d+1} (0,{\Sigma}_{\f,\bm{\theta}^\star_{\f}})
%\end{alignat*}

%\begin{enumerate}
%\only<1>{\item ‘‘Oracle'': $\sqrt[]{n+n'} ( \hat{\bm{\theta}} - \bm{\theta}^\star ) \xrightarrow[n,n' \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,{\Sigma}_{\bm{\theta}^\star})$}
%\only<2>{\item ‘‘Oracle'': $\textcolor{red}{\sqrt[]{n+n'}} ( \hat{\bm{\theta}} - \bm{\theta}^\star ) \xrightarrow[n,n' \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,{\Sigma}_{\bm{\theta}^\star})$}
%\only<3>{\item ‘‘Oracle'': $\sqrt[]{n+n'} ( \hat{\bm{\theta}} - \textcolor{red}{\bm{\theta}^\star} ) \xrightarrow[n,n' \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,{\Sigma}_{\bm{\theta}^\star})$}
%\only<4>{\item ‘‘Oracle'': $\sqrt[]{n+n'} ( \hat{\bm{\theta}} - \bm{\theta}^\star ) \xrightarrow[n,n' \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,\textcolor{red}{{\Sigma}_{\bm{\theta}^\star}})$}
%\only<5->{\item ‘‘Oracle'': $\textcolor{red}{\sqrt[]{n+n'}} ( \hat{\bm{\theta}} - \textcolor{red}{\bm{\theta}^\star} ) \xrightarrow[n,n' \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,\textcolor{red}{{\Sigma}_{\bm{\theta}^\star}})$}
%
%\only<1>{\item Current methodology: $ \sqrt[]{n} ( \hat{\bm{\theta}}_{\f} - \bm{\theta}^\star_{\f} ) \xrightarrow[n \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,{\Sigma}_{\f,\bm{\theta}^\star_{\f}})$}
%\only<2>{\item Current methodology: $ \textcolor{red}{\sqrt[]{n}} ( \hat{\bm{\theta}}_{\f} - \bm{\theta}^\star_{\f} ) \xrightarrow[n \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,{\Sigma}_{\f,\bm{\theta}^\star_{\f}})$}
%\only<3>{\item Current methodology: $ \sqrt[]{n} ( \hat{\bm{\theta}}_{\f} - \textcolor{red}{\bm{\theta}^\star_{\f}} ) \xrightarrow[n \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,{\Sigma}_{\f,\bm{\theta}^\star_{\f}})$}
%\only<4>{\item Current methodology: $ \sqrt[]{n} ( \hat{\bm{\theta}}_{\f} - \bm{\theta}^\star_{\f} ) \xrightarrow[n \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,\textcolor{red}{{\Sigma}_{\f,\bm{\theta}^\star_{\f}}})$}
%\only<5->{\item Current methodology: $ \textcolor{red}{\sqrt[]{n}} ( \hat{\bm{\theta}}_{\f} - \textcolor{red}{\bm{\theta}^\star_{\f}} ) \xrightarrow[n \to \infty]{\mathcal{L}} \mathcal{N}_{d+1} (0,\textcolor{red}{{\Sigma}_{\f,\bm{\theta}^\star_{\f}}})$}
%
%\end{enumerate}

%\bigskip
%
%\bigskip
%
%\uncover<5->{
%\textbf{\textcolor{red}{Question 1} :} asymptotics of the estimators
%
%{\centering{\fbox{(Q1) $ {\bm{\theta}}^\star \stackrel{?}{=} {{\bm{\theta}}}^\star_{\f} $}}}
%
%%\fbox{(Q2) \centering{${\Sigma}_{\bm{\theta}^\star} \stackrel{?}{=} {\Sigma}_{\f,\bm{\theta}^\star_{\f}} $}}
%
%}
%
%\uncover<6->{
%\textbf{\textcolor{red}{Question 2} :} bla
%}
%
%\end{frame}

%----------------------------------------------------------------------------------------



%----------------------------------------------------------------------------------------

%\subsection*{Model specification}
%
%\begin{frame}
%\frametitle{\secname : \subsecname}
%
%\begin{itemize}
%\item \textbf{Well-specified model} : $p(y|\bm{x}) = p_{\bm{\theta}^\star}(y|\bm{x})$.
%
%$\rightarrow$ With real data $\Rightarrow$ hypothesis unlikely to be true.
%\item \textbf{Misspecified model} : $\bm{\theta}^\star$ is the ``best'' in the $\Theta$ family.
%
%$\rightarrow$ Logistic regression commonly used for its robustness to misspecification (no assumption about $p(\bm{x})$).
%\end{itemize}
%
%\footnotesize{
%\begin{table}[ht]
%\begin{tabular}{|R{3cm}||C{2cm}|C{2cm}|}
%\hline \backslashbox{$p_{\bm{\theta}}(y|\bm{x})$}{$p(z|\bm{x},y)$} & MAR & MNAR \\
%\hline
%\hline Well specified & $\textcolor{olive}{\bm{\theta}^\star_{\f} = \bm{\theta}^\star}$ & \multirow{2}{*}{\textcolor{red}{$\bm{\theta}^\star_{\f} \neq \bm{\theta}^\star$}} \\ \cline{1-2}
% Misspecified & \textcolor{red}{$\bm{\theta}^\star_{\f} \neq \bm{\theta}^\star$} & \\
%\hline 
%\end{tabular}
%\label{tableasymptotic}
%\caption{(Q1) w.r.t. model specification and missingness mechanism}
%\end{table}
%}
%
%\end{frame}
%
%%----------------------------------------------------------------------------------------
%
%\subsection{How to use $\mathbf{x}_{\nf}$?}
%
%\begin{frame}
%\frametitle{\secname : \subsecname}
%
%\uncover<1->{
%\textbf{\textcolor{red}{Question 2}:} How to construct a better estimator than $\hat{\bm{\theta}}_{\f}$?
%}
%
%\bigskip
%
%\bigskip
%
%\uncover<2->{
%\textbf{\textcolor{red}{Scope for action}:}
%}
%\begin{itemize}
%\only<2-5>{\item Change model space $\Theta$,}
%\only<6->{\item \sout{Change model space $\Theta$} logistic regression,}
%\only<3-6>{\item Model acceptance/rejection process (i.e. $p_{\gamma}(z|\bm{x},y)$),}
%\only<7->{\item \sout{Model acceptance/rejection process (i.e. $p_{\gamma}(z|\bm{x},y)$)}
%
%$\gamma$ cannot be estimated,}
%\item<4-> Use $\mathbf{x}_{\nf}$.
%\end{itemize}
%
%\only<5>{
%\begin{block}{Natural way to achieve all three: generative approach}
%\setlength\abovedisplayskip{-5pt}
%\begin{flalign*}
%& \hspace{0.4cm} {p_{\textcolor{red}{\alpha}}(\bm{x},y,z) = p_{\beta_{\textcolor{red}{\alpha}}}(\bm{x}) p_{\theta_{\textcolor{red}{\alpha}}}(y|x) p_{\gamma_{\textcolor{red}{\alpha}}}(z|\bm{x},y).} &
%\end{flalign*}
%\begin{alignat*}{2}
%& (\fbox{$\hat{\theta}_{\textcolor{red}{\alpha}}$},\hat{\beta}_{\textcolor{red}{\alpha}},\hat{\gamma}_{\textcolor{red}{\alpha}}) && = \argmax_{{{\theta}_{\textcolor{red}{\alpha}}},\beta_{\textcolor{red}{\alpha}},\gamma_{\textcolor{red}{\alpha}}} \ell({\textcolor{red}{\alpha}};\bm{x},\bm{y}_{\f}) = \argmax_{{{\theta}_{\textcolor{red}{\alpha}}},\beta_{\textcolor{red}{\alpha}},\gamma_{\textcolor{red}{\alpha}}} \sum_{i=1}^{n }\ln(p_{\theta_{\textcolor{red}{\alpha}}}(y_i|x_i)) \\
%& && + \sum_{i=1}^{n+n'} \ln(p_{\beta_{\textcolor{red}{\alpha}}}(\bm{x}_i)) \left( + \sum_{i=1}^{n} \ln(p_{\gamma_{\textcolor{red}{\alpha}}}(z_i|x_i,y_i)) \right).
%\end{alignat*}
%\end{block}
%}
%\only<6>{
%\begin{block}{\sout{Natural way to achieve all three: generative approach}}
%\setlength\abovedisplayskip{-5pt}
%\begin{flalign*}
%& \hspace{0.4cm} {p_{\textcolor{red}{\alpha}}(\bm{x},y,z) = p_{\beta_{\textcolor{red}{\alpha}}}(\bm{x}) p_{\theta_{\textcolor{red}{\alpha}}}(y|\bm{x}) p_{\gamma_{\textcolor{red}{\alpha}}}(z|\bm{x},y).} &
%\end{flalign*}
%\begin{alignat*}{2}
%& (\fbox{$\hat{\theta}_{\textcolor{red}{\alpha}}$},\hat{\beta}_{\textcolor{red}{\alpha}},\hat{\gamma}_{\textcolor{red}{\alpha}}) && = \argmax_{\textcolor{red}{\alpha}} \ell({\textcolor{red}{\alpha}};\bm{x},\bm{y}_{\f}) = \argmax_{{{\theta}_{\textcolor{red}{\alpha}}},\beta_{\textcolor{red}{\alpha}},\gamma_{\textcolor{red}{\alpha}}} \sum_{i=1}^{n}\ln(p_{\theta_{\textcolor{red}{\alpha}}}(y_i|x_i)) \\
%& && + \sum_{i=1}^{n+n'} \ln(p_{\beta_{\textcolor{red}{\alpha}}}(\bm{x}_i)) \left( + \sum_{i=1}^{n} \ln(p_{\gamma_{\textcolor{red}{\alpha}}}(z_i|x_i,y_i)) \right).
%\end{alignat*}
%\end{block}
%}
%
%\uncover<8->{
%%\begin{tikzpicture}
%%\coordinate (A) at (-1,1);
%%\coordinate (B) at (3,0.5);
%%\coordinate (C) at (4,-1);
%%\coordinate (D) at (1,-1);
%%\foreach \p in {A,B,C,D}
%%{\draw[fill=white] (\p) circle (1pt);}
%%\DrawPotato[blue,fill=red]{A}{B}{C}{D}
%%\end{tikzpicture}
%
%{\bf Remember} that $\mathcal{T}^{\text{OOT}}$ also comes from $p(y | \bm{x}, \f)$ such that applying a \textit{Reject Inference} method and getting a higher Gini is no guarantee that it would on the Through-the-Door population (on the contrary!).
%}
%
%\end{frame}





%\begin{frame}
%\frametitle{\secname: \subsecname}
%
%They usually amount to EM-like algorithms:
%\setbeamercolor{normal text}{fg=black}
%\usebeamercolor[fg]{normal text}
%\hspace*{-0.7cm} \[ \textcolor{white}{\mathcal{T}_{\text{c}}^{(1)} = } %\left(
%\begin{array}{c}
%\tikzmarkin[hor=style green]{el0} \mathbf{x}_{\f} \tikzmarkend{el0} \\
%\\
%\\
%\tikzmarkin[hor=style green]{el-1} \mathbf{x}_{\nf} \tikzmarkend{el-1} \end{array}
%%\left( 
%\begin{array}{ccc}
%\tikzmarkin[hor=style green]{el1} \; \; x_{1,1} & \cdots & x_{1,d}  \\
% \vdots & \vdots & \vdots \\
% x_{n,1} & \cdots & x_{n,d} \\
% x_{n+1,1} & \cdots & x_{n+1,d}  \\
% \vdots & \vdots & \vdots \\
% x_{n+n',1} & \cdots & x_{n+n',d} \tikzmarkend{el1} \end{array},
% \hspace{0.2cm}
% \begin{array}{c}
%\tikzmarkin[hor=style green]{l1} \mathbf{y}_{\f} \tikzmarkend{l1}\\
%\\
%\\
%\tikzmarkin[hor=style green]{l2} \mathbf{y}_{\nf} \tikzmarkend{l2} \end{array}
%%\left( 
%\begin{array}{c}
%\tikzmarkin[hor=style green]{l3} \; \; y_1 \; \; \; \\
%\vdots \\
% y_n \\ 
% \hat{y}_{n+1}^{(1)} \\
%\vdots \\
%\hat{y}_{n+n'}^{(1)} \tikzmarkend{l3}\end{array},
%\hspace{0.2cm} 
% \begin{array}{c}
%\tikzmarkin[hor=style green]{el111} \mathbf{z}_{\f} \tikzmarkend{el111}\\
%\\
%\\
%\tikzmarkin[hor=style green]{el121} \mathbf{z}_{\nf} \tikzmarkend{el121}\end{array}
%%\left( 
%\begin{array}{c}
%\tikzmarkin[hor=style green]{e41} \text{f} \\
%\vdots \\
%\text{f} \\ 
%\text{nf} \\
%\vdots \\
%\text{nf} \tikzmarkend{e41} \end{array}.\]
% 
%\setbeamercolor{normal text}{fg=white}
%\usebeamercolor[fg]{normal text}
%
%\end{frame}

 
 
 
 
 
%\begin{frame}
%\frametitle{\secname : \subsecname}
%
%\textbf{Reclassification}\footnote{\cite{RI6,banasik,saporta}} :
%\[(\hat{\bm{\theta}}^{\text{CEM}}, \textcolor{red}{\hat{\mathbf{y}}^{\nf}}) = \argmax_{\bm{\theta},\textcolor{red}{\mathbf{{y}}^{\nf}}} \ell(\bm{\theta}; \mathcal{T}_c^{(1)}) \text{ where } \textcolor{red}{\hat{y_i}} = \argmax_{y_i} p_{\hat{\bm{\theta}}_{\f}}(y_i|\bm{x}_i).\]
%\textbf{Problem:} inconsistent estimator.
%
%\vspace*{0.2cm}
%\hspace*{-0.8cm} \centering \includegraphics[width=12cm]{figures/CEM_bias.png}
%
%\end{frame}
%
%%----------------------------------------------------------------------------------------
%
%\begin{frame}
%\frametitle{\secname : \subsecname}
%
%\textbf{Augmentation}\footnote{\cite{RI6,banasik,saporta,economix}}: MAR / misspecified model.
%\[ \ell_{\text{Aug}}(\bm{\theta}; \mathcal{T}_\f) = \sum_{i=1}^n \textcolor{red}{\frac{1}{p(\text{f}|\bm{x}_i)}} \ln(p_{\bm{\theta}}(y_i|\bm{x}_i)).\]
%\textbf{Problem:} estimation of $p(\text{f}|x_i)$ + assumes $p(\text{f}|x_i) > 0$ (clearly not true).
%
%\medskip
%
%\noindent\makebox[\linewidth]{\rule{\paperwidth}{1pt}}
%
%\medskip
%
%\textbf{Parcelling} \footnote{\cite{RI6,banasik,saporta}}:
%\[ \ell(\theta; \bm{x},\mathbf{y}_{\f},\textcolor{red}{\mathbf{\hat{y}}_{\nf}}) \text{ where } \textcolor{red}{\hat{y_i}} = \begin{cases} 1 \text{ w.p. } \textcolor{red}{\alpha_i} p_{\hat{\bm{\theta}}_{\f}}(1|\bm{x}_i,\text{f}) \\ 0 \text{ w.p. } 1-\textcolor{red}{\alpha_i} p_{\hat{\bm{\theta}}_{\f}}(1|\bm{x}_i,\text{f}) \end{cases}. \]
%
%\textbf{Problem:} MNAR assumptions hidden in $\textcolor{red}{\mathbf{\hat{y}}_{\nf}}$ ($\textcolor{red}{\alpha_i}$) impossible to test.
%
%\end{frame}



 
%\subsection{Additional remarks} 
% 
%\begin{frame}
%\frametitle{\secname: \subsecname}
%
%\begin{animateinline}[autoplay,loop]{2}%
%{\color{red}{\bf WARNING}}%
%\newframe \end{animateinline}
%
%\medskip
%
%All this stands for logistic regression and all ``local'' methods~\cite{zadrozny2004learning}.
%
%\medskip
%
%All ``global'' methods (explicit or implicit modelling of $p(\bm{x})$) will produce biased estimates under MAR.
%
%\medskip
%
%We might have:
%
%\begin{table}[t]
%\centering
%\begin{tabular}{l || l | l}
%Gini & Logistic regression & Decision trees \\
%\hline
%Financed & 40 & 45 \\
%\textcolor{red}{Through-the-door} & 40 & 35 \\
%\end{tabular}
%\end{table}
%
%\end{frame}






\section{Feature quantization}


\subsection{by an example}

{
\setbeamercolor{background canvas}{bg=white}
\begin{frame}
\frametitle{\secname: \subsecname}

\begin{figure}[!ht]
\begin{animateinline}[poster=first, controls=all, palindrome, autopause, autoresume, width=\textwidth, height=6cm]{3}
\multiframe{99}{i=2+1}{\input{CODE_FIGURES/EXAMPLE_DISC/disc_plot\i.tex}}%
\end{animateinline}
\end{figure}

\end{frame}
}


\subsection{some more notations}

\begin{frame}[allowframebreaks]
\frametitle{\secname: \subsecname}

%\begin{block}{Raw data}
%\vspace*{-0.9cm}
%\begin{align*}
%\bx & =(x_1,\dots,x_d) \\
%x_j & \in \mathbb{R} \text{ (continuous case)} \\
%x_j & \in \{1,\dots,l_j\} \text{ (categorical case)} \\
%y & \in \{0,1\} \text{ (target)}
%\end{align*}
%\vspace*{-0.7cm}
%\end{block}
%
%\bigskip

\begin{block}{Quantized data}
\vspace*{-0.9cm}
\begin{align*}
\q(\bx) & = (\q_1(x_1),\dots,\q_d(x_d)) \\
\q_j(x_j) & = (\s_{j,h}(x_j))_1^{m_j} \text{ (one-hot encoding)} \\
\s_{j,h}(\cdot) & = \mathds{1}(x_j \in C_{j,h}), 1 \leq h \leq m_j
%\s_{j,h}(\cdot) & =  1 \text{ if } x_j \in C_{j,h}, 0 \text{ otherwise, } 1 \leq h \leq m_j
\end{align*}
\vspace*{-0.7cm}
\end{block}

\begin{animateinline}[autoplay,loop]{2}%
{\color{red}{\bf Huge cardinality!}}%
\newframe \end{animateinline}

\pagebreak

\begin{block}{Discretization}
\vspace*{-0.4cm}
\[C_{j,h}=(c_{j,h-1},c_{j,h}]\]

where $c_{j,1},\ldots,c_{j,m_j-1}$ are increasing numbers called cutpoints, $c_{j,0}=-\infty$ and $c_{j,m_j}=+\infty$.
\end{block}

\bigskip

\begin{center}
\begin{tikzpicture}[scale=0.3]
\draw[->,line width=0.1cm] (-5,0)--(24,0) node[right]{$x_j$};

\node [red,circle, fill] at (4,0) {};
\node [red,circle, fill] at (12,0) {};

\node at (4,-1.5) {$c_{j,1}$};
\node at (12,-1.5) {$c_{j,2}$};

\node at (-1,1) {$(1,0,0)$};
\node at (8,1) {$(0,1,0)$};
\node at (19,1) {$(0,0,1)$};

\end{tikzpicture}
\end{center}

\pagebreak

\begin{block}{Grouping}
\vspace*{-0.4cm}
\[\bigsqcup_{h=1}^{m_j}C_{j,h}=\{1,\ldots,l_j\}.\]
\vspace*{-0.2cm}
\end{block}

\bigskip

\begin{center}
\begin{tikzpicture}[scale=0.25,every node/.style={scale=0.9}]
\tikzset{vertex/.style = {shape=circle,draw,scale=0.7,minimum size=1cm}}
\tikzset{edge/.style = {->,> = latex'}}

% Boules E^j
\node [vertex] (e1) at (3,4) {$(1,0)$};
\node [vertex] (e2) at (15,4) {$(0,1)$};

% Boules X^J
\node [vertex] (x1) at (-4,0) {1};
\node [vertex] (x2) at (1.8,0) {2};
\node [vertex] (x3) at (9.5,0) {3};
\node [vertex] (x4) at (17,0) {4};
\node [vertex] (x5) at (24,0) {5};

% Labels
\node at (-7,4) {$\q_j(x_j)=$};
\node at (-7,0) {$x_j=$};

% Flèches
\draw[edge,line width=0.03cm] (x1) to (e1);
\draw[edge,line width=0.03cm] (x3) to (e1);
\draw[edge,line width=0.03cm] (x4) to (e1);
\draw[edge,line width=0.03cm] (x2) to (e2);
\draw[edge,line width=0.03cm] (x5) to (e2);

\end{tikzpicture}
\end{center}

\begin{block}{Oracle}
\vspace*{-0.4cm}
\begin{align*}
\bm{\theta}^\star, \q^\star = & \argmax_{\bm{\theta} \in \bm{\Theta}_{\textcolor{yellow}{\q}}, \textcolor{yellow}{\q \in \bm{Q}}} \mathbb{E}_{\bm{x},y} \left[\ln p_{\bm{\theta}}(y | \q(\bm{x}))\right], \\
\hat{\bm{\theta}}^{\text{BIC}}, \hat{\q}^{\text{BIC}} = & \argmin_{\bm{\theta} \in \bm{\Theta}_{\textcolor{yellow}{\q}}, \textcolor{yellow}{\q \in \bm{Q}}} \text{BIC}(\hat{\bm{\theta}}_{\q}; \bm{\mathbf{y}}_{\text{f}}, \q(\bm{\mathbf{x}}_{\text{f}})), \\
& \text{where } \hat{\bm{\theta}}_{\q} = \argmax_{\bm{\theta} \in \bm{\Theta}_{\textcolor{yellow}{\q}}} \ell(\bm{\theta} ; \bm{\mathbf{y}}_{\text{f}}, \q(\bm{\mathbf{x}}_{\text{f}})).
\end{align*}
\vspace*{-0.2cm}
\end{block}

\end{frame}






\subsection{existing approaches}
\begin{frame}
\frametitle{\secname: \subsecname}

\vspace*{-0.25cm}
\begin{center}
\includegraphics[scale=0.3]{figures/taxonomy.PNG}
\end{center}
\vspace*{-0.2cm}
These approaches (\cite{wrapper2}) maximize an ``intermediary'' criterion, \textit{e.g.}:
\vspace*{-0.1cm}
\[ \hat{\q}_j^{\chi^2} = \argmax_{\q_j} \chi^2(\q_j(\mathbf{x}_\text{f}), \mathbf{y}_\text{f}) \stackrel{?}{\approx} \q^\star_j, \]
\vspace*{-0.1cm}
and we {\bf hope} that it's aligned with our original goal s.t.:
\vspace*{-0.1cm}
\[ \hat{\bm{\theta}}^{\chi^2} = \argmax_{\bm{\theta}} \ell(\bm{\theta} ; \mathbf{y}_\text{f}, {\hat{\q}^{\chi^2}}(\mathbf{x}_\text{f})) \stackrel{?}{\approx} \bm{\theta}^\star. \]

\end{frame}





\subsection{approximation}
\begin{frame}
\frametitle{\secname: \subsecname}

\begin{equation*}
    \q_{\ag_j}(\cdot)=\left(q_{\ag_{j,h}}(\cdot)\right)_{h=1}^{m_j} \text{ with } \begin{cases} \sum_{h=1}^{m_j}q_{\ag_{j,h}}(\cdot)=1, \\ 0 \leq q_{\ag_{j,h}}(\cdot) \leq 1, \end{cases}
\end{equation*}

\uncover<2->{

\textbf{For continuous features}, we set for $\bm{\alpha}_{j,h} = (\alpha^0_{j,h},\alpha^1_{j,h}) \in \mathbb{R}^2$
\[\s_{\ag_{j,h}}(\cdot) = \frac{\exp(\alpha^0_{j,h} + \alpha^1_{j,h}  \cdot)}{\sum_{g=1}^{m_j} \exp(\alpha^0_{j,g} + \alpha^1_{j,g}  \cdot)}.\]
}
\uncover<3->{
\textbf{For categorical features}, we set for $\bm{\alpha}_{j,h}=\left(\alpha_{j,h}(1),\ldots, \alpha_{j,h}(l_j)\right) \in \mathbb{R}^{l_j}$
\[\s_{\ag_{j,h}}(\cdot) = \frac{\exp\left(\alpha_{j,h}(\cdot)\right)}{\sum_{g=1}^{m_j} \exp\left(\alpha_{j,g}(\cdot)\right)}.\]
}

\end{frame}





\subsection{estimation MAP}
\begin{frame}
\frametitle{\secname : \subsecname}
\vspace*{-0.2cm}

\[ \hat{\s}_{j,h}(x_j) = 1 \text{ if } h = \argmax_{1 \leq h' \leq m_j} \s_{\hat{\ag}_{j,h'}}, 0 \text{ otherwise.} \]

\begin{tikzpicture}[scale=0.9]
\begin{axis}[
  no markers, domain=-1.5:2, samples=100,
  axis lines*=left,
  every axis y label/.style={at=(current axis.left of origin), anchor=north west},
  height=3cm, width=11cm,
  xtick=\empty, ytick=\empty,
  enlargelimits=false, clip=false,
  x label style={at={(axis description cs:0.5,0)},anchor=north},
  y label style={at={(axis description cs:-0.1,.5)},rotate=90,anchor=south},
  xlabel={$x_j$},
  ylabel={$\s_{\hat{\ag}_{j,1}}(x_j)$}
  ]
    
  \addplot [very thick,white] {gauss(-1.8,0.6)};
\addplot+[mark=none,thick,red] coordinates {(-0.7,0) (-0.7,0.6)};
\addplot+[mark=none,thick,red] coordinates {(1,0) (1,0.6)};
\node at (axis cs:-1.1,0.4) {$\hat{\s}_{j,1}(x_j)=1$};
\node at (axis cs:0,0.4) {$\hat{\s}_{j,1}(x_j)=0$};
\node at (axis cs:1.5,0.4) {$\hat{\s}_{j,1}(x_j)=0$};
\node at (axis cs:-0.7,-0.15) {$\hat{c}_{j,1}$};
\node at (axis cs:1,-0.15) {$\hat{c}_{j,2}$};

\end{axis}
\end{tikzpicture}

\begin{tikzpicture}[scale=0.9]
\begin{axis}[
  no markers, domain=-1.5:2, samples=100,
  axis lines*=left,
  every axis y label/.style={at=(current axis.left of origin), anchor=north west},
  height=3cm, width=11cm,
  xtick=\empty, ytick=\empty,
  enlargelimits=false, clip=false,
  x label style={at={(axis description cs:0.5,0)},anchor=north},
  y label style={at={(axis description cs:-0.1,.5)},rotate=90,anchor=south},
  xlabel={$x_j$},
  ylabel={$\s_{\hat{\ag}_{j,2}}(x_j)$}
  ]
    
  \addplot [very thick,white] {gauss(0,0.6)};
\addplot+[mark=none, thick,red] coordinates {(-0.7,0) (-0.7,0.6)};
\addplot+[mark=none, thick,red] coordinates {(1,0) (1,0.6)};
\node at (axis cs:-1.1,0.4) {$\hat{\s}_{j,2}(x_j)=0$};
\node at (axis cs:0,0.4) {$\hat{\s}_{j,2}(x_j)=1$};
\node at (axis cs:1.5,0.4) {$\hat{\s}_{j,2}(x_j)=0$};
\node at (axis cs:-0.7,-0.15) {$\hat{c}_{j,1}$};
\node at (axis cs:1,-0.15) {$\hat{c}_{j,2}$};

\end{axis}

\end{tikzpicture}

\begin{tikzpicture}[scale=0.9]
\begin{axis}[
  no markers, domain=-1.5:2, samples=100,
  axis lines*=left,
  every axis y label/.style={at=(current axis.left of origin), anchor=north west},
  height=3cm, width=11cm,
  xtick=\empty, ytick=\empty,
  enlargelimits=false, clip=false,
  x label style={at={(axis description cs:0.5,0)},anchor=north},
  y label style={at={(axis description cs:-0.1,.5)},rotate=90,anchor=south},
  xlabel={$x_j$},
  ylabel={$\s_{\hat{\ag}_{j,3}}(x_j)$}
  ]
    
  \addplot [very thick,white] {gauss(2,0.6)};

\addplot+[mark=none, thick,red] coordinates {(-0.7,0) (-0.7,0.6)};
\addplot+[mark=none, thick,red] coordinates {(1,0) (1,0.6)};

\node at (axis cs:-1.1,0.4) {$\hat{\s}_{j,3}(x_j)=0$};
\node at (axis cs:0,0.4) {$\hat{\s}_{j,3}(x_j)=0$};
\node at (axis cs:1.5,0.4) {$\hat{\s}_{j,3}(x_j)=1$};
\node at (axis cs:-0.7,-0.15) {$\hat{c}_{j,1}$};
\node at (axis cs:1,-0.15) {$\hat{c}_{j,2}$};

\end{axis}
\end{tikzpicture}


\end{frame}





\subsection{neural networks}

\begin{frame}
\frametitle{\secname: \subsecname}

We wish to maximize the following likelihood:
\[ (\hat{\bm{\theta}}, \hat{\bm{\alpha}}) = \argmax_{\bm{\theta}, \bm{\alpha}} \ell(\bm{\theta}, \bm{\alpha} ; \bm{\mathbf{x}}_\f, \bm{\mathbf{y}}_\f) = \argmax_{\bm{\theta}, \bm{\alpha}} \sum_{i=1}^n \ln p_{\bm{\theta}}(y_i | \q_{\alpha}(\bm{x}_i)). \]

\medskip

{\bf If there is a true quantization} $\q^\star$, then $\bm{\alpha}^\star = \lim_{n \to \infty} \hat{\bm{\alpha}}$ is such that $\q_{\bm{\alpha}^\star} = \q^\star$.

\medskip

\uncover<2->{
{\bf If not}, $\hat{\q}$ is ``guaranteed'' to be a good candidate quantization.
}

\medskip

\uncover<3->{
{\bf Problem:} $\ell(\bm{\theta}, \bm{\alpha} ; \bm{\mathbf{x}}_\f, \bm{\mathbf{y}}_\f)$ cannot be directly maximized (it's not even convex).
}

\medskip

\uncover<4->{
{\bf Solution:} Resort to gradient descent (not guaranteed to converge to a global maximum!).
}

\end{frame}






\begin{frame}
\frametitle{\secname: \subsecname}

\def\layersep{2.5cm}

\centering
\begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=\layersep]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]
    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]
    \tikzstyle{input neuron}=[neuron, fill=green!50];
    \tikzstyle{output neuron}=[neuron, fill=red!50];
    \tikzstyle{hidden neuron}=[neuron, fill=blue!50];
    \tikzstyle{annot} = [text width=4em, text centered]
    \tikzstyle{annotrectangle} = [text width=8em, text centered]


        \node[input neuron, pin=left:Continuous input \#1] (I-1) at (0,-1) {};
        
        \node[input neuron, pin=left:Level \#1] (I-2) at (0,-2) {};
        \node[input neuron, pin=left:Level \#2] (I-3) at (0,-3) {};
        \node[input neuron, pin=left:Level \#3] (I-4) at (0,-4) {};

    % Draw the hidden layer nodes
    \foreach \name / \y in {1,...,2}
        \path[yshift=0.5cm]
            node[hidden neuron] (H-\name) at (\layersep,-\y cm) {Soft};

    \foreach \name / \y in {3,...,4}
        \path[yshift=0.5cm]
            node[hidden neuron] (H-\name) at (\layersep,-\y cm) {Soft};

    % Draw the output layer node
    \node[output neuron,pin={[pin edge={->}]right:Output}, right of=H-2] (O) {$\sigma$};

    % Connect every node in the input layer with every node in the
    % hidden layer.
%    \foreach \source in {1,...,4}
        \foreach \dest in {1,2}
            \path (I-1) edge (H-\dest);

        \foreach \dest in {3,4}
            \path (I-2) edge (H-\dest);
        \foreach \dest in {3,4}
            \path (I-3) edge (H-\dest);
        \foreach \dest in {3,4}
            \path (I-4) edge (H-\dest);

        % \foreach \dest in {5,6}
        %     \path (I-3) edge (H-\dest);

    % Connect every node in the hidden layer with the output layer
    \foreach \source in {1,...,4}
        \path (H-\source) edge (O);

    % Annotate the layers
    \node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer};
    \node[annot,left of=hl] {Input layer};
    \node[annot,right of=hl] {Output layer};
    
    
    \draw [orange] (2,0) rectangle (3,-1.9);
    % \draw [red] (2,-2) rectangle (3,-4);
    
    \node[annotrectangle,right of=H-1, node distance=2.5cm] {Softmax outputs are $\q_{{\ag}_j}(x_j)$.}; 
    

\end{tikzpicture}

\end{frame}





%\begin{frame}
%\frametitle{\secname: \subsecname}

% \newlength\figureheight
% \newlength\figurewidth
% \setlength\figureheight{3cm}
% \setlength\figurewidth{\textwidth}


%  \begin{figure}[!ht]
%    \centering
%    \begin{subfigure}[t]{\textwidth}
%        \centering
%        \input{True_simulated_data/feature_0_iteration_5.tex}
%        \vspace{-0.5cm}
%        \caption{Quantization $\hat{\q}^{(s)}_1({x}_1)$ resulting from the MAP at iter $t = 5$ and $m_{\text{max}} = 3$.}
%    \end{subfigure}%
%    
%    \begin{subfigure}[t]{\textwidth}
%        \centering
%        \input{True_simulated_data/feature_0_iteration_300.tex}
%        \vspace{-0.5cm}
%        \caption{Quantizations $\hat{\q}^{(s)}_1({x}_1)$ resulting from the MAP at iter $t = 300$ and $m_{\text{max}} = 3$.}
%    \end{subfigure}
%    
%    \caption{\label{fig:MAP} Quantizations $\hat{\q}^{(s)}_1({x}_1)$ of experiment (a) resulting from the thresholding (\ref{eq:ht}).}
%\end{figure}

%\end{frame}



\newlength\figureheight
\newlength\figurewidth
\setlength\figureheight{7cm}
\setlength\figurewidth{12cm}
 
\begin{frame}
\frametitle{\secname: \subsecname}

\begin{figure}
\hspace*{-1cm}
\begin{animateinline}[poster=first, controls, buttonfg=white]{3}
\multiframe{200}{i=1+1}{\input{CODE_FIGURES/GLMDISC_NN/feature_0_iteration_\i.tex}}%
\end{animateinline}
\end{figure}

\end{frame}



\subsection{model = quantization selection}

\begin{frame}
\frametitle{\secname : \subsecname}

\begin{block}{New model selection criterion}
We have drastically restricted the search space to \textit{iter} well-chosen candidates resulting from the the gradient descent steps.
\[ s^\star = \argmin_{s = 1, \ldots, \textit{iter}} \text{BIC}(\hat{\bth}_{\hat{\q}^{(s)}}) \]
\end{block}

\medskip

\uncover<2->{
We would still need to loop over candidates $\textcolor{yellow}{\bm{m}}$!
}

\medskip

\uncover<3->{
In practice if $\forall i, \; q_{\alpha_{j,h}}(x_j) \ll 1$, then level $h$ disappears while performing the $\argmax$.
}

\medskip

\uncover<4->{
Start with $\bm{m} = (m_{\text{max}})_1^d$ and ``wait'' \dots
}


\end{frame}



%\subsection{SEM-Gibbs}
%
%\begin{frame}
%\frametitle{\secname : \subsecname}
%
%Originally (and as implemented in the \textsc{R} package glmdisc), the optimization was a bit different:
%\begin{itemize}
%\item<2-> $\q$ is considered a latent (unobserved) feature;
%\item<3-> A classical EM algorithm is intractable since it requires an Expectation step over all possible quantizations;
%\item<4-> Solution: random draw $\approx$ Bayesian statistics;
%\end{itemize}
%
%\end{frame}
%
%
%\begin{frame}
%\frametitle{\subsecname: estimation}
%
%``Classical'' estimation strategy with latent variables: EM algorithm.
%
%\bigskip
%
%\uncover<2->{
%There would still be a sum over $\bm{\mathcal{Q}}_{\bm{m}}$: $p(y|\bm{x},\bm{\theta},\bm{\alpha}) = \sum_{\q \in \bm{\mathcal{Q}}_{\bm{m}}} p_{\bm{\theta}}(y|\q) \prod_{j=1}^d p_{\bm{\alpha}_j}(\q_j|x_j)$
%}
%
%\bigskip
%
%\uncover<3->{
%Use a Stochastic-EM! Draw $\q$ knowing that:
%}
%\medskip
%\uncover<4->{
%\[p(\q|\bm{x},y) = \underbrace{\dfrac{p_{\bm{\theta}}(y|\q) \prod_{j=1}^d p_{\bm{\alpha_j}}(\q_j|x_j)}{\sum_{\bm{q} \in \bm{\mathcal{Q}}_{\bm{m}}} p_{\bm{\theta}}(y|\q) \prod_{j=1}^d p_{\bm{\alpha}_j}(\q_j|x_j)}}_{\text{still difficult to calculate}}\]
%}
%\medskip
%\uncover<5->{
%Gibbs-sampling step:
%\[p(\q_j|\bm{x},y,\q_{\{-j\}}) \propto p_{\bm{\theta}}(y|\q) p_{\bm{\alpha_j}}(\q_j|x_j)\]
%}
%
%
%\end{frame}
%
%
%
%
%\begin{frame}
%\frametitle{\subsecname: algorithm}
%
%\tiny
%
%
%\textbf{Initialization}
%
%
%\medskip
%
%$\left( \begin{array}{ccc}
%x_{1,1} & \cdots & x_{1,d}  \\
% \vdots & \vdots & \vdots \\
% x_{n,1} & \cdots & x_{n,d} \end{array} \right)
%\begin{array}{c}
%\text{at random} \\
%\Rightarrow \end{array}
%\left( \begin{array}{ccc}
%\q_{1,1} & \cdots & \q_{1,d}  \\
% \vdots & \vdots & \vdots \\
% \q_{n,1} & \cdots & \q_{n,d} \end{array} \right)$
%
%\medskip
%
%\textbf{Loop}
%
%\medskip
%
%$\left( \begin{array}{c}
%y_1 \\
%\vdots \\
%y_n \end{array} \right)
%\begin{array}{c}
%\text{logistic} \\
%\text{regression} \\
%\Rightarrow \end{array}
%\left( \begin{array}{ccc}
%\q_{1,1} & \cdots & \q_{1,d}  \\
% \vdots & \vdots & \vdots \\
% \q_{n,1} & \cdots & \q_{n,d} \end{array} \right)
%\begin{array}{c}
%\text{polytomous} \\
%\text{regression} \\
%\Rightarrow \end{array}
%\left( \begin{array}{ccc}
%x_{1,1} & \cdots & x_{1,d}  \\
% \vdots & \vdots & \vdots \\
% x_{n,1} & \cdots & x_{n,d} \end{array} \right)
%$
%
%\medskip
%
%\textbf{Updating $\q$}
%
%\medskip
%
%$\left( \begin{array}{c}
%p(y_1,\q_{1,j}=k|\bm{x}_i)  \\
%\vdots \\
%p(y_n,\q_{n,j}=k|\bm{x}_i) \end{array} \right)
%\begin{array}{c}
%\text{random} \\
%\text{sampling} \\
%\Rightarrow \end{array}
%\left( \begin{array}{ccc}
%\q_{1,j}  \\
% \vdots \\
% \q_{n,j} \end{array} \right)$
%
%\medskip
%
%\textbf{Calculating $\q^{\text{MAP}}$}
%
%\medskip
%
%$\left( \begin{array}{c}
%\q^{\text{MAP},1,j}  \\
%\vdots \\
%\q^{\text{MAP},n,j} \end{array} \right)
%\begin{array}{c}
%\text{MAP} \\
%\text{estimate} \\
%= \end{array}
%\left( \begin{array}{ccc}
%\argmax_{\q_j} p_{\bm{\alpha_j}}(\q_j | x_{1,j})  \\
% \vdots \\
%\argmax_{\q_j} p_{\bm{\alpha_j}}(\q_j | x_{n,j}) \end{array} \right)$
% 
% 
%\normalsize
%
%\end{frame}
%
%
%
%
%
%
%\begin{frame}
%\frametitle{\secname}
%
%\begin{figure}
%%\begin{animateinline}[poster=first, controls, palindrome, buttonfg=white]{5}
%%\multiframe{200}{i=1+1}{\input{CODE_FIGURES/GLMDISC_SEM/sem_feature_1_iter_\i.tex}}%
%%\end{animateinline}
%\end{figure}
%
%\end{frame}





\subsection{results}

\begin{frame}

\frametitle{\secname: \subsecname}

Simulated data

\medskip

\begin{table}[ht]
    \centering
    \caption{For different sample sizes $n$, (A) CI of $\hat{c}_{j,2}$ for $c_{j,2} = 2/3$. (B) CI of $\hat{m}$ for $m_1=3$. (C) CI of $\hat{m}_3$ for $m_3=1$.}
    \label{tab:estim_precision}
\begin{tabular}{llllll}
$n$ & (A) $\hat{c}_{j,2}$ & (B) & $\hat{m}_1$ & (C) & $\hat{m}_3$ \\
\hline
$1{,}000$ & $[0.656,0.666]$ & \myobar{1}{90}{9} & \mybar{60}{32}{8} \\
$10{,}000$ & $[0.666,0.666]$ & \myobar{0}{100}{0} & \mybar{88}{12}{0}
\end{tabular}
\end{table}

\end{frame}




%\begin{frame}
%
%\frametitle{\secname: \subsecname}
%
%UCI data
%
%\medskip
%
%\begin{table}
%    \centering
%        \caption{Gini indices (the greater the value, the better the performance) of our proposed quantization algorithm \textit{glmdisc} and two baselines: ALLR and MDLP / $\chi^2$ tests obtained on several benchmark datasets from the UCI library.}
%    \label{tab:banchmark}
%\begin{tabular}{llll}
%Dataset & ALLR & MDLP/$\chi^2$ & \textit{glmdisc} \\
%\hline
%Adult & 81.4 (1.0) & \textcolor{green}{85.3} (0.9) & 80.4 (1.0) \\
%Australian & 72.1 (10.4) & 84.1 (7.5) & \textcolor{green}{92.5} (4.5) \\
%Bands & 48.3 (17.8) & 47.3 (17.6) & \textcolor{green}{58.5} (12.0) \\
%Credit & 81.3 (9.6) & 88.7 (6.4) & \textcolor{green}{92.0} (4.7) \\
%German & 52.0 (11.3) & 54.6 (11.2) & \textcolor{green}{69.2} (9.1) \\
%Heart & 80.3 (12.1) & 78.7 (13.1) & \textcolor{green}{86.3} (10.6)
%\end{tabular}
%\end{table}
%
%
%\end{frame}
%
%
%
%\begin{frame}
%
%\frametitle{\secname: \subsecname}
%
%CACF data
%
%\medskip
%
%\begin{table}
%    \centering
%        \caption{Gini indices (the greater the value, the better the performance) of our proposed quantization algorithm \textit{glmdisc}, the two baselines of Table~\ref{tab:banchmark} and the current scorecard (manual / expert representation) obtained on several portfolios of Cr\'edit Agricole Consumer Finance.}
%    \label{tab:real_data}
%\resizebox{.86\textwidth}{!}{\begin{tabular}{lllll}
%Portfolio & ALLR & Current & MDLP/$\chi^2$ & \textit{glmdisc} \\
%\hline
%Automobile & \textcolor{green}{59.3} (3.1) & 55.6 (3.4) & \textcolor{green}{59.3} (3.0) & 58.9 (2.6) \\
%Renovation & 52.3 (5.5) & 50.9 (5.6) & 54.0 (5.1) & \textcolor{green}{56.7} (4.8) \\
%Standard & 39.7 (3.3) & 37.1 (3.8) & \textcolor{green}{45.3} (3.1) & 44.0 (3.1) \\
%Revolving & 62.7 (2.8) & 58.5 (3.2) & \textcolor{green}{63.2} (2.8) & 62.3 (2.8) \\
%Mass retail & 52.8 (5.3) & 48.7 (6.0) & 61.4 (4.7) & \textcolor{green}{61.8} (4.6) \\
%Electronics & 52.9 (11.9) & 55.8 (10.8) & 56.3 (10.2)  & \textcolor{green}{72.6} (7.4)
%\end{tabular}}
%\end{table}
%
%%See \href{https://gist.github.com/adimajo/eb007492007d650091f6bd7cb2047493}{this gist} for $\chi^2$ automated grouping tests.
%
%\end{frame}






\section{Bivariate interactions}

\subsection{notations}

\begin{frame}<presentation:0>[noframenumbering]
\frametitle{\secname: \subsecname}

Upper triangular matrix with $\delta_{k,\ell} = 1 $ if $k < \ell$ and features $k$ and $\ell$ ``interact'' in the logistic regression.
\[ \text{logit}(p_{\bm{\theta}}(1|\q(\bm{x}))) = \theta_0 + \sum_{j=1}^{d} \theta_j^{\q_j(x_j)} + \sum_{1\leq k < \ell \leq d} \delta_{k,\ell} \theta_{k,\ell}^{\q_k(x_k) f_{\ell}(x_{\ell})} \]
\uncover<2->{
Imagine for now that the discretization $\q(\bm{x})$ is fixed. The criterion becomes:
\begin{align*}
(\bm{\theta}^\star,\bm{\delta}^\star) & = \argmax_{\bm{\theta},\textcolor{yellow}{\bm{\delta} \in \{0,1\}^\frac{d(d-1)}{2}}} \sum_{i=1}^n \ln p_{\bm{\theta}}(y_i|\q(\bm{x}_i),\bm{\delta}) - \text{penalty}(n;\bm{\theta}) 
\end{align*}
}
\uncover<3->{
Analogous to previous problem: $2^{\frac{d(d-1)}{2}}$ models.
}


\end{frame}

\subsection{model proposal}
\begin{frame}<presentation:0>[noframenumbering]
\frametitle{\secname: \subsecname}

$\delta$ is latent and hard to optimize over: use a stochastic algorithm!

\bigskip

\uncover<2->{
Strategy used here: Metropolis-Hastings sampling algorithm.

{\bf Idea:} propose well-chosen interactions and accept / reject them based on the BIC criterion of the resulting logistic regression.
}

\only<3>{
\begin{align*}
p(y|\bqk ) & = \sum_{\bm{\delta} \in \{0,1\}^\frac{d(d-1)}{2}} p(y | \bqk, \bm{\delta}) p(\bm{\delta}) \\
p(\bm{\delta} | \bqk,y) & \propto \exp(-\text{BIC}[\bm{\delta}]/2) p(\bm{\delta})
\end{align*}
}
\uncover<4->{
\begin{align*}
p(y| \bqk ) & = \sum_{\bm{\delta} \in \{0,1\}^\frac{d(d-1)}{2}} p(y | \bqk, \bm{\delta}) p(\bm{\delta}) \\
p(\bm{\delta} | \bqk,y) & \propto \exp(-\text{BIC}[\bm{\delta}]/2) \textcolor{yellow}{\cancel{p(\bm{\delta})}} \hspace{1cm} p(\delta_{p,q}) = \frac{1}{2}
\end{align*}
}
\uncover<5->{
Which transition proposal $\tr: ({\{0,1\}}^{\frac{d(d-1)}{2}},{\{0,1\}}^{\frac{d(d-1)}{2}}) \mapsto [0 ; 1]$?
}

\end{frame}

\begin{frame}<presentation:0>[noframenumbering]
\frametitle{\secname: \subsecname}

$2^{d(d-1)}$ probabilities to calculate\dots

\bigskip

\uncover<2->{
\textbf{We restrict changes to only one entry $\delta_{k,\ell}$.}
}

\bigskip

\uncover<3->{
\textbf{Proposal:} gain/loss in BIC between \textcolor{yellow}{bivariate} models \textcolor{yellow}{with} / \textcolor{yellow}{without} the interaction.
}

\bigskip

\uncover<4->{
If the interaction between two features is meaningful when only these two features are considered, there is a good chance that it will be in the full multivariate model.
}

\bigskip

\uncover<5->{
\textbf{Trick:} alternate one discretization  / grouping step and one ``interaction'' step.
}

\end{frame}









\subsection{results}

\begin{frame}
\frametitle{\secname: \subsecname}

Données UCI

\begin{table}
    \centering
        \caption{Gini indices (the greater the value, the better the performance) of our proposed quantization algorithm \textit{glmdisc} and two baselines.}
    \label{tab:banchmark_inter}
\resizebox{\textwidth}{!}{
\begin{tabular}{llllll}
Dataset & ALLR & \textit{ad hoc} methods & \makecell{Our proposal:\\ \textit{glmdisc}-NN} & \makecell{Our proposal:\\ \textit{glmdisc}-SEM} & \makecell{\textit{glmdisc}-SEM\\ w.\ interactions} \\
\hline
Adult & 81.4 (1.0) & \textcolor{green}{\textbf{85.3}} (0.9) & 80.4 (1.0) & 81.5 (1.0) & 81.5 (1.0 - no interaction) \\
Australian & 72.1 (10.4) & 84.1 (7.5) & 92.5 (4.5) & \textcolor{green}{\textbf{100}} (0) & \textcolor{green}{\textbf{100}} (0 - no interaction) \\
Bands & 48.3 (17.8) & 47.3 (17.6) & 58.5 (12.0) & \textcolor{green}{\textbf{58.7}} (12.0) & \textcolor{green}{\textbf{58.8}} (13.0) \\
Credit & 81.3 (9.6) & 88.7 (6.4) & \textcolor{green}{\textbf{92.0}} (4.7) & 87.7 (6.4) & 87.7 (6.4 - no interaction) \\
German & 52.0 (11.3) & 54.6 (11.2) & \textcolor{green}{\textbf{69.2}} (9.1) & 54.5 (10) &  \\
Heart & 80.3 (12.1) & 78.7 (13.1) & \textcolor{green}{\textbf{86.3}} (10.6) & 82.2 (11.2) & 84.5 (10.8)
\end{tabular}
}
\end{table}

\end{frame}



\begin{frame}
\frametitle{\secname : \subsecname}

Medicine data

\begin{table}[t]
\begin{center}
\caption{Gini indices of our proposed quantization algorithm \textit{glmdisc}-SEM and two baselines.}
\label{tab:banchmark_medicine}
\begin{adjustbox}{max width=0.99\textwidth}
\begin{tabular}{rrrrr}
 & Pima & Breast & Birthwt \\ 
  \hline
ALLR & {\textcolor{green}{\textbf{73.0}}} & 94.0 & 34.0 \\ 
ALLR LR w. interactions & 60.0 & 51.0 & 15.0 \\ 
glmdisc & 57.0 & 93.0 & 18.0 \\ 
glmdisc w. interactions & 62.0 & \textcolor{green}{\textbf{95.0}} & \textcolor{green}{{\textbf{54.0}}}\\ 
\end{tabular}
\end{adjustbox}
\end{center}
\end{table}


\end{frame}




\begin{frame}
\frametitle{\secname : \subsecname}

CACF data

\begin{table}
    \centering
        \caption{Gini indices (the greater the value, the better the performance) of our proposed quantization algorithm \textit{glmdisc}, the two baselines and the current scorecard.}
    \label{tab:real_data_inter}
\resizebox{\textwidth}{!}{
\begin{tabular}{lllllll}
Portfolio & ALLR & \makecell{Current\\performance} & \makecell{\textit{ad hoc}\\methods} & \makecell{Our proposal:\\ \textit{glmdisc}-NN} & \makecell{Our proposal:\\ \textit{glmdisc}-SEM} & \makecell{\textit{glmdisc}-SEM\\ w.\ interactions} \\
\hline
Automobile & 59.3 (3.1) & 55.6 (3.4) & 59.3 (3.0) & 58.9 (2.6) & 57.8 (2.9) & \textcolor{green}{\bf{64.8}} (2.0) \\
Renovation & 52.3 (5.5) & 50.9 (5.6) & 54.0 (5.1) & \textcolor{green}{\bf{56.7}} (4.8) & 55.5 (5.2) & 55.5 (5.2) \\
Standard & 39.7 (3.3) & 37.1 (3.8) & 45.3 (3.1) & 43.8 (3.2) & 36.7 (3.7) & \textcolor{green}{\bf{47.2}} (2.8) \\
Revolving & 62.7 (2.8) & 58.5 (3.2) & 63.2 (2.8) & 62.3 (2.8) & 60.7 (2.8) & \textcolor{green}{\bf{67.2}} (2.5) \\
Mass retail & 52.8 (5.3) & 48.7 (6.0) & 61.4 (4.7) & \textcolor{green}{\bf{61.8}} (4.6) & 61.0 (4.7) & 60.3 (4.8) \\
Electronics & 52.9 (11.9) & 55.8 (10.8) & 56.3 (10.2)  & \textcolor{green}{\bf{72.6}} (7.4) & 62.0 (9.5) & 63.7 (9.0) \\
\end{tabular}
}
\end{table}


\end{frame}




\begin{frame}
\frametitle{\secname : \subsecname}

Older results

\begin{table}[t]
\begin{center}
\begin{adjustbox}{max width=0.99\textwidth}

\begin{tabular}{|c||c|c|c|c|}
\hline  Gini & Current performance & \textbf{glmdisc} & Basic \textbf{glm} \\
\hline
\hline   Auto (n=50,000 ; d=15) & 57.9 & \textcolor{green}{64.84} & 58\\
\hline   Revolving (n=48,000 ; d=9) & 58.57 & \textcolor{green}{67.15} & 53.5 \\
\hline   Prospects (n=5,000 ; d=25) & 35.6 & \textcolor{green}{47.18} & 32.7\\
\hline   Electronics (n=140,000 ; d=8) & \textcolor{green}{57.5} & \textcolor{green}{58} & -10 \\
\hline   Young (n=5,000 ; d=25) & $\approx$ 15 & \textcolor{green}{30} & 12.2 \\
\hline   Basel II (n=70,000 ; d=13) & \textcolor{green}{70} & \textcolor{green}{71.3} & 19 \\
\hline 
\end{tabular}

\end{adjustbox}
\end{center}
\end{table}


\end{frame}





\section{Segmentation: logistic regression trees}

{\setbeamercolor{background canvas}{bg=white}
\setbeamercolor{normal text}{fg=black!90}
\begin{frame}
\frametitle{\secname}

\tikzstyle{level 1}=[level distance=1.5cm, sibling distance=9cm]
\tikzstyle{level 2}=[level distance=1.5cm, sibling distance=4.5cm]
\tikzstyle{level 3}=[level distance=2cm, sibling distance=3.5cm]

\begin{figure}
\centering

\resizebox{\linewidth}{!}{\begin{tikzpicture}
  [
    sibling distance        = 15em,
    level distance          = 5em,
    edge from parent/.style = {draw = black, -latex},
    every node/.style       = {font=\footnotesize},
    sloped
  ]
  \node [root] {\textcolor{black}{Clients}}
    child { node [dummy] {}
      child { node [dummy] {}
        child { node [env] {\textcolor{black}{$p_{\theta_1}(y|\bm{q}_{\{1\}}(\bm{x}_{\{1\}}))$}}
          edge from parent node [below] {\textcolor{black}{Renters}} }
        child { node [env] {\textcolor{black}{$p_{\theta_2}(y|\bm{q}_{\{2\}}(\bm{x}_{\{2\}}))$}}
          edge from parent node [above] {\textcolor{black}{Workers}} }
        child { node [env] {\textcolor{black}{$p_{\theta_3}(y|\bm{q}_{\{3\}}(\bm{x}_{\{3\}}))$}}
                edge from parent node [above] {\textcolor{black}{Others}} }
        edge from parent node [above] {\textcolor{black}{Revolving}} }
      child { node [env] {\textcolor{black}{$p_{\theta_4}(y|\bm{q}_{\{4\}}(\bm{x}_{\{4\}}))$}}
              edge from parent node [above, align=center]
                {\textcolor{black}{Standard}} }
              edge from parent node [above] {\textcolor{black}{Appliances}} }
    child { node [dummy] {}
      child { node [dummy] {}
        child { node [env] {\textcolor{black}{$p_{\theta_5}(y|\bm{q}_{\{5\}}(\bm{x}_{\{5\}}))$}}
          edge from parent node [above] {\textcolor{black}{Leasing}} }
        child { node [env] {\textcolor{black}{$p_{\theta_6}(y|\bm{q}_{\{6\}}(\bm{x}_{\{6\}}))$}}
                edge from parent node [above] {\textcolor{black}{Standard}} }
        edge from parent node [above] {\textcolor{black}{Fiat}} }
      child { node [env] {\textcolor{black}{$p_{\theta_7}(y|\bm{q}_{\{7\}}(\bm{x}_{\{7\}}))$}}
              edge from parent node [above, align=center]
                {\textcolor{black}{Kawasaki}} }
              edge from parent node [above] {\textcolor{black}{Cars}} };
\end{tikzpicture}}
\caption{\textcolor{black}{Scorecards tree structure in acceptance system.} }
\label{fig:arbre}
\end{figure}
\end{frame}
}



\begin{frame}
\frametitle{\secname}

Current procedure(s):
\begin{itemize}
\item<2-> Promise a new partner their own score to maximize acceptance;
\item<3-> Merge existing ``close'' branches that show similar performance;
\item<4-> Try basic ``clustering'' techniques, \textit{e.g.}\ MCA.
\end{itemize}

\bigskip

\uncover<5->{
Problem(s):
\begin{itemize}
\item<6-> This structure is not the result of optimization and is probably suboptimal (by how much?);
\item<7-> There are situations in which it severely fails.
\end{itemize}
}

\end{frame}






\begin{frame}
\frametitle{\secname}

\hspace*{-2cm}\resizebox{1.2\textwidth}{!}{
\begin{tikzpicture}[
    declare function={a(\x)=0.75*\x-2;},
    declare function={b(\x)=0.75*\x-1;}
]


\begin{axis}[xtick=\empty, ytick=\empty, xlabel={Revenus}, ylabel={Endettement}]
\myGlobalTransformation{0}{0};

% pauvres
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+x};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+x+2.5};

%moyens
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=2:6]{rand+x};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=2:6]{rand+x+2.5};

%riches
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=7:11]{rand+x};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=7:11]{rand+x+2.5};

%frontière
\addplot [white, very thick, domain=-3:11] {x+1.25};
\end{axis}


\end{tikzpicture}
}

\end{frame}




\begin{frame}
\frametitle{\secname}

\begin{tikzpicture}


\begin{axis}[xtick=\empty, ytick=\empty, xlabel={Revenus}, ylabel={Endettement},domain=-3:1, enlargelimits=false,ymin=-3,ymax=6]
\myGlobalTransformationbis{0}{0};

% techniciens
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand};
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand-2};
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand-4};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+2.5};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+4.5};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+6.5};

%frontière
\addplot [white, very thick, domain=-3:1] {1.25};
\end{axis}





\begin{axis}[xtick=\empty, ytick=\empty, xlabel={Revenus}, ylabel={Endettement},domain=-3:1, enlargelimits=false,ymin=-3,ymax=6]
\myGlobalTransformationbis{0}{3};

% cadres
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand-x};
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand-x-2};
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand-x-4};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand-x+2.5};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand-x+4.5};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand-x+6.5};

%frontière
\addplot [white, very thick, domain=-3:1] {-x+1.25};
\end{axis}



\begin{axis}[xtick=\empty, ytick=\empty, xlabel={Revenus}, ylabel={Endettement},domain=-3:1, enlargelimits=false,ymin=-3,ymax=6]
\myGlobalTransformationbis{0}{6};

% libérales
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+x};
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+x-2};
\addplot [green, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+x-4};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+x+2.5};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+x+4.5};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+x+6.5};
\addplot [red, only marks, mark=*, samples=300, mark size=0.75,domain=-3:1]{rand+x+8.5};

%frontière
\addplot [white, very thick, domain=-3:1] {x+1.25};
\end{axis}



\end{tikzpicture}

\end{frame}



\subsection{notations}

\begin{frame}
\frametitle{\secname: \subsecname}

$K$ segments.

\medskip

\uncover<2->{
$c \in \{1, \dots, K\}$: latent feature of the client's segment.
}

\medskip

\uncover<2->{
$\mathbf{c} = (c_1, \dots, c_n)$: segment for all $n$ clients.
}


\medskip

\uncover<3->{
We suppose there is a true segmentation $K^\star, \mathbf{c}^\star$ and logistic regressions $\bm{\theta}^{\star, c^\star}$ at its leaves.
}

\medskip

\uncover<4->{
If we could evaluate all segmentations, the best one could be selected by
\[ (\hat{K}, \hat{\mathbf{c}}) = \argmax_{K,\mathbf{c}} \sum_{c=1}^K \text{BIC}(\hat{\bm{\theta}}^{c} ; \{(\bm{x}_i,y_i) | c_{i} = c, 1 \leq i \leq n\}),\]
where $\hat{\bm{\theta}}^c$ is the MLE of the logistic regression of segment $c$.
}

\end{frame}



\subsection{model proposal}

\begin{frame}
\frametitle{\secname: \subsecname}

Similarly to the quantization proposal: ability to be in several segments at a time.

\medskip

\uncover<2->{
\[ p(y| \bm{x}) = \sum_{c=1}^K p_{\bm{\theta}}(y | \bm{x}; c) p_{\beta}(c | \bm{x}).\]
}

\medskip

\uncover<3->{
\[ c_i^{(s+1)} \sim p_{\bm{\theta}^{\cdot(s)}}(y_i | \bm{x}_i; \cdot) p_{\beta^{(s)}}(\cdot | \bm{x}_i). \]
}

\medskip

\uncover<4->{
\[ \bm{\theta}^{c(s+1)} = \argmax_{\bm{\theta}^c} \sum_{i=1}^n \mathds{1}_{c}(c_i^{s+1)}) \ln p_{\bm{\theta}^c}(y_i | \bm{x}_i ; c_i). \]
}

\medskip

\uncover<5->{
\[ \beta^{(s+1)} = \text{C4.5}(\mathbf{c}^{(s+1)}, \mathbf{x}) .\]
}

\end{frame}

\subsection{some results}

\begin{frame}
\frametitle{\secname: \subsecname}

\begin{table}[t]
\centering
\begin{tabular}{ll|lllll}
 & Oracle = ALLR & \textit{glmtree}-SEM & FAMD & PLS & LMT & MOB \\
\hline
Gini & 69.7 & \textcolor{green}{\textbf{69.7}} & 65.3 & 47.0 & \textcolor{green}{\textbf{69.7}} & 64.8 \\
\end{tabular}
\end{table}

\bigskip

\begin{table}[t]
\centering
\begin{tabular}{ll|llllll}
 & Oracle & ALLR & \textit{glmtree}-SEM & FAMD & PLS & LMT & MOB \\
\hline
Gini & 69.7 & 25.8 & \textcolor{green}{\textbf{69.7}} & 17.7 & 48.4 & 65.8 & \textcolor{green}{\textbf{69.7}} \\
\end{tabular}
\end{table}

\end{frame}



%\section{Bonus}
%
%
%\begin{frame}[allowframebreaks]
%\frametitle{\secname}
%
%\textbf{Big ``unstructured'' data}
%
%Some theoretical results about an ever bigger $d$ (not the one you think about though).
%
%\bigskip
%
%\textbf{Online logistic regression}
%
%What if we dynamically adjusted logistic regression coefficients of a given scorecard (still learnt on a cold database) on new data as they come in?
%
%\pagebreak
%
%\textbf{Profitability}
%
%Good / bad label is merely a proxy of the true performance measure: profitability.
%
%\underline{Already done}: weighting observations by the amount of the loan gives rise to roughly the same logistic regression coefficients.
%
%\bigskip
%
%\textbf{Predicting IR3 in 2 months based on the month's applications}
%
%Current process: finance people, wait 3 months, if risk $\neq$ budget then adjust acceptance policy, wait 3 months again and repeat.
%
%Couldn't we anticipate by looking at the quality (\textit{e.g.}\ through the score) of the applications?
%
%\end{frame}

\section{Conclusion and future work}

\subsection{Conclusion}

\begin{frame}
\frametitle{\subsecname}

This PhD tackled three main issues of ``traditional'' Credit Scoring:
\begin{enumerate}
\item Reject inference: impact of tossing away not-financed clients,

\medskip

\only<2>{Conclusion: sound problem reformulation, no method recommended, \lstinline{scoringTools} \textsc{R} package.}
\item<3-> ``Constrained'' representation learning: discretization, grouping, interaction screening,

\medskip

\only<4>{Conclusion: better performance, less time-consuming, some guarantees, \lstinline{glmdisc} \textsc{R} package.}
\item<5-> Predictive segmentation: logistic regression trees,

\medskip

\only<6>{Conclusion: first experiments on simulated and real data are encouraging, \lstinline{glmtree} \textsc{R} package.}
\end{enumerate}

\end{frame}


\subsection{Future work}

\begin{frame}
\frametitle{\subsecname}

There remains a lot of open questions:
\begin{enumerate}
\item Predictive segmentation: logistic regression trees,

\medskip

\only<2>{Perspective: allow for quantization / interaction screening and feature selection at each iteration.}
\item<3-> Credit Scoring for profit: swap ``$p($2 unpaid instalments$)$'' for $p($profit$>0)$ or $\mathbb{E}[\text{profit}]$,

\medskip

\only<4>{Perspective: experiment observation-wise misclassification costs.}
\item<5-> Representation learning for fine-grained unstructured data,

\medskip

\only<6>{Perspective: provide statistically sound methods to aggregate ``behavioural'' data, \textit{e.g.}\ web visitation patterns.}
\end{enumerate}

\end{frame}



\begin{frame}

\Huge

Thanks!

\end{frame}


\begin{frame}[allowframebreaks]
\frametitle{References}
\begin{scriptsize}
\printbibliography
\end{scriptsize}
\end{frame}



\end{document}


